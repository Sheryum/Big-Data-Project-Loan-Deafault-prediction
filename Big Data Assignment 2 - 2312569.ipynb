{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "377abd31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59b1f02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "540f8aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training and testing data\n",
    "train_data = pd.read_csv(\"trainData.csv\")\n",
    "test_data = pd.read_csv(\"testData.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfe7159",
   "metadata": {},
   "source": [
    " PreProcessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0780df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "train_data['y'] = train_data['loan_status'].apply(lambda x: 1 if x == 'Charged Off' else 0)\n",
    "\n",
    "#Dropping the Id member_id columns as they dont have any information usefull to the model\n",
    "train_data.drop(columns=['id', 'member_id','loan_status'], inplace=True)\n",
    "test_data.drop(columns=['id', 'member_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1462f96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables\n",
    "cat_cols = ['grade', 'emp_length', 'home_ownership', 'application_type']\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    train_data[col] = le.fit_transform(train_data[col])\n",
    "    test_data[col] = le.fit_transform(test_data[col])\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30a8bef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns and their number of null values:\n",
      "loan_amnt                          0\n",
      "int_rate                           0\n",
      "installment                        0\n",
      "grade                              0\n",
      "emp_length                         0\n",
      "home_ownership                     0\n",
      "annual_inc                         0\n",
      "dti                              180\n",
      "delinq_2yrs                        5\n",
      "inq_last_6mths                     5\n",
      "mths_since_last_delinq        115840\n",
      "open_acc                           5\n",
      "pub_rec                            5\n",
      "revol_bal                          0\n",
      "revol_util                       190\n",
      "total_acc                          5\n",
      "total_pymnt                        0\n",
      "total_pymnt_inv                    0\n",
      "total_rec_prncp                    0\n",
      "total_rec_int                      0\n",
      "total_rec_late_fee                 0\n",
      "recoveries                         0\n",
      "collection_recovery_fee            0\n",
      "last_pymnt_amnt                    0\n",
      "collections_12_mths_ex_med        16\n",
      "application_type                   0\n",
      "acc_now_delinq                     5\n",
      "tot_coll_amt                    7107\n",
      "tot_cur_bal                     7107\n",
      "total_rev_hi_lim                7107\n",
      "y                                  0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Display columns with their corresponding number of null values\n",
    "null_counts = train_data.isnull().sum()\n",
    "print(\"Columns and their number of null values:\")\n",
    "print(null_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ae2fce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mths_since_last_delinq variable is important feature to check for default but has 50% null values.\n",
    "#Replacing the NULL values with 0 assuming that while data collection the values were missed because of no delinquencies occuring\n",
    "\n",
    "\n",
    "train_data['mths_since_last_delinq'].fillna(train_data['mths_since_last_delinq'].mean(), inplace=True)\n",
    "test_data['mths_since_last_delinq'].fillna(test_data['mths_since_last_delinq'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2009d8e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame after removing rows with null values: (218604, 31)\n",
      "Shape of DataFrame after removing rows with null values: (218720, 31)\n"
     ]
    }
   ],
   "source": [
    "#Replacing the rows where column has null values\n",
    "\n",
    "train_data.dropna(inplace=True)\n",
    "test_data.dropna(inplace=True)\n",
    "\n",
    "# Check the shape of the DataFrame after removing rows with null values\n",
    "print(\"Shape of DataFrame after removing rows with null values:\", train_data.shape)\n",
    "print(\"Shape of DataFrame after removing rows with null values:\", test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1edf50c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'loan_amnt' is numeric: True\n",
      "Column 'int_rate' is numeric: True\n",
      "Column 'installment' is numeric: True\n",
      "Column 'grade' is numeric: True\n",
      "Column 'emp_length' is numeric: True\n",
      "Column 'home_ownership' is numeric: True\n",
      "Column 'annual_inc' is numeric: True\n",
      "Column 'dti' is numeric: True\n",
      "Column 'delinq_2yrs' is numeric: True\n",
      "Column 'inq_last_6mths' is numeric: True\n",
      "Column 'mths_since_last_delinq' is numeric: True\n",
      "Column 'open_acc' is numeric: True\n",
      "Column 'pub_rec' is numeric: True\n",
      "Column 'revol_bal' is numeric: True\n",
      "Column 'revol_util' is numeric: True\n",
      "Column 'total_acc' is numeric: True\n",
      "Column 'total_pymnt' is numeric: True\n",
      "Column 'total_pymnt_inv' is numeric: True\n",
      "Column 'total_rec_prncp' is numeric: True\n",
      "Column 'total_rec_int' is numeric: True\n",
      "Column 'total_rec_late_fee' is numeric: True\n",
      "Column 'recoveries' is numeric: True\n",
      "Column 'collection_recovery_fee' is numeric: True\n",
      "Column 'last_pymnt_amnt' is numeric: True\n",
      "Column 'collections_12_mths_ex_med' is numeric: True\n",
      "Column 'application_type' is numeric: True\n",
      "Column 'acc_now_delinq' is numeric: True\n",
      "Column 'tot_coll_amt' is numeric: True\n",
      "Column 'tot_cur_bal' is numeric: True\n",
      "Column 'total_rev_hi_lim' is numeric: True\n",
      "Column 'y' is numeric: True\n"
     ]
    }
   ],
   "source": [
    "numeric_columns = train_data.select_dtypes(include='number').columns\n",
    "\n",
    "# Check if each column is numeric\n",
    "for column in train_data.columns:\n",
    "    is_numeric = column in numeric_columns\n",
    "    print(f\"Column '{column}' is numeric: {is_numeric}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fea6a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation of variables with 'loan_status':\n",
      "y                             1.000000\n",
      "recoveries                    0.523448\n",
      "collection_recovery_fee       0.504759\n",
      "grade                         0.224438\n",
      "total_rec_prncp               0.213357\n",
      "int_rate                      0.199086\n",
      "last_pymnt_amnt               0.173894\n",
      "total_pymnt_inv               0.129822\n",
      "total_pymnt                   0.129816\n",
      "total_rec_late_fee            0.100838\n",
      "inq_last_6mths                0.090857\n",
      "revol_util                    0.066026\n",
      "total_rev_hi_lim              0.057935\n",
      "application_type              0.051395\n",
      "tot_cur_bal                   0.051248\n",
      "home_ownership                0.047306\n",
      "total_rec_int                 0.038889\n",
      "dti                           0.035348\n",
      "annual_inc                    0.033073\n",
      "pub_rec                       0.031546\n",
      "installment                   0.027409\n",
      "loan_amnt                     0.020313\n",
      "open_acc                      0.020041\n",
      "revol_bal                     0.019001\n",
      "delinq_2yrs                   0.017902\n",
      "total_acc                     0.017877\n",
      "emp_length                    0.013985\n",
      "acc_now_delinq                0.011173\n",
      "mths_since_last_delinq        0.006298\n",
      "collections_12_mths_ex_med    0.004578\n",
      "tot_coll_amt                  0.000463\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "Correlation = train_data.corrwith(train_data['y'])\n",
    "abs_correlation = Correlation.abs().sort_values(ascending=False)\n",
    "print(\"Correlation of variables with 'loan_status':\")\n",
    "print(abs_correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae12a61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values if any\n",
    "# For simplicity droping rows with missing values\n",
    "train_data.dropna(inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# Split data into features and target variable\n",
    "#Training set\n",
    "X_train = train_data.drop(columns=['y'])\n",
    "y_train = train_data['y']\n",
    "\n",
    "\n",
    "#Test set\n",
    "X_test = test_data.drop(columns=['loan_status'])\n",
    "y_test = test_data['loan_status'].apply(lambda x: 1 if x == 'Charged Off' else 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29430c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping 3 low correlation variables\n",
    "#tot_coll_amt\n",
    "#collections_12_mths_ex_med\n",
    "#mths_since_last_delinq\n",
    "X_train = X_train.drop(columns=['tot_coll_amt','collections_12_mths_ex_med','mths_since_last_delinq'])\n",
    "X_test = X_test.drop(columns=['tot_coll_amt','collections_12_mths_ex_med','mths_since_last_delinq'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "577f960e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>grade</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>dti</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>...</th>\n",
       "      <th>total_rec_prncp</th>\n",
       "      <th>total_rec_int</th>\n",
       "      <th>total_rec_late_fee</th>\n",
       "      <th>recoveries</th>\n",
       "      <th>collection_recovery_fee</th>\n",
       "      <th>last_pymnt_amnt</th>\n",
       "      <th>application_type</th>\n",
       "      <th>acc_now_delinq</th>\n",
       "      <th>tot_cur_bal</th>\n",
       "      <th>total_rev_hi_lim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8000</td>\n",
       "      <td>7.07</td>\n",
       "      <td>247.28</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>78000.0</td>\n",
       "      <td>19.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8000.00</td>\n",
       "      <td>325.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6844.48</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200412.0</td>\n",
       "      <td>16800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20000</td>\n",
       "      <td>7.21</td>\n",
       "      <td>619.47</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>78000.0</td>\n",
       "      <td>23.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3041.18</td>\n",
       "      <td>659.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>619.47</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39187.0</td>\n",
       "      <td>42100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20000</td>\n",
       "      <td>12.74</td>\n",
       "      <td>452.41</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>97000.0</td>\n",
       "      <td>5.52</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6215.08</td>\n",
       "      <td>4217.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>452.41</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>279688.0</td>\n",
       "      <td>6500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20000</td>\n",
       "      <td>8.81</td>\n",
       "      <td>634.23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>115000.0</td>\n",
       "      <td>16.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20000.00</td>\n",
       "      <td>6.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20015.91</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>172493.0</td>\n",
       "      <td>40200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9000</td>\n",
       "      <td>19.20</td>\n",
       "      <td>330.82</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>7.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9000.00</td>\n",
       "      <td>422.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8761.49</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28658.0</td>\n",
       "      <td>20000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_amnt  int_rate  installment  grade  emp_length  home_ownership  \\\n",
       "0       8000      7.07       247.28      0           1               1   \n",
       "1      20000      7.21       619.47      0           3               5   \n",
       "2      20000     12.74       452.41      2           5               1   \n",
       "3      20000      8.81       634.23      0           1               1   \n",
       "5       9000     19.20       330.82      3           6               5   \n",
       "\n",
       "   annual_inc    dti  delinq_2yrs  inq_last_6mths  ...  total_rec_prncp  \\\n",
       "0     78000.0  19.25          0.0             0.0  ...          8000.00   \n",
       "1     78000.0  23.06          0.0             0.0  ...          3041.18   \n",
       "2     97000.0   5.52          1.0             0.0  ...          6215.08   \n",
       "3    115000.0  16.84          0.0             2.0  ...         20000.00   \n",
       "5     60000.0   7.28          0.0             0.0  ...          9000.00   \n",
       "\n",
       "   total_rec_int  total_rec_late_fee  recoveries  collection_recovery_fee  \\\n",
       "0         325.02                 0.0         0.0                      0.0   \n",
       "1         659.62                 0.0         0.0                      0.0   \n",
       "2        4217.64                 0.0         0.0                      0.0   \n",
       "3           6.12                 0.0         0.0                      0.0   \n",
       "5         422.98                 0.0         0.0                      0.0   \n",
       "\n",
       "   last_pymnt_amnt  application_type  acc_now_delinq  tot_cur_bal  \\\n",
       "0          6844.48                 0             0.0     200412.0   \n",
       "1           619.47                 0             0.0      39187.0   \n",
       "2           452.41                 0             0.0     279688.0   \n",
       "3         20015.91                 0             0.0     172493.0   \n",
       "5          8761.49                 0             0.0      28658.0   \n",
       "\n",
       "   total_rev_hi_lim  \n",
       "0           16800.0  \n",
       "1           42100.0  \n",
       "2            6500.0  \n",
       "3           40200.0  \n",
       "5           20000.0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f26586e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>grade</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>dti</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>...</th>\n",
       "      <th>total_rec_prncp</th>\n",
       "      <th>total_rec_int</th>\n",
       "      <th>total_rec_late_fee</th>\n",
       "      <th>recoveries</th>\n",
       "      <th>collection_recovery_fee</th>\n",
       "      <th>last_pymnt_amnt</th>\n",
       "      <th>application_type</th>\n",
       "      <th>acc_now_delinq</th>\n",
       "      <th>tot_cur_bal</th>\n",
       "      <th>total_rev_hi_lim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18600</td>\n",
       "      <td>10.99</td>\n",
       "      <td>608.86</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>12.92</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>18600.0</td>\n",
       "      <td>1355.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15705.09</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>170238.0</td>\n",
       "      <td>20700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000</td>\n",
       "      <td>17.97</td>\n",
       "      <td>72.28</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>55400.0</td>\n",
       "      <td>10.62</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>128.9</td>\n",
       "      <td>83.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.28</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>351452.0</td>\n",
       "      <td>10800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12000</td>\n",
       "      <td>12.29</td>\n",
       "      <td>400.24</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>17.92</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12000.0</td>\n",
       "      <td>485.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11281.15</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18207.0</td>\n",
       "      <td>20600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16000</td>\n",
       "      <td>19.42</td>\n",
       "      <td>589.90</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>64000.0</td>\n",
       "      <td>3.90</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3561.4</td>\n",
       "      <td>2303.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>589.90</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12293.0</td>\n",
       "      <td>7800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22525</td>\n",
       "      <td>16.02</td>\n",
       "      <td>548.01</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>94080.0</td>\n",
       "      <td>19.08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>22525.0</td>\n",
       "      <td>2226.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21483.11</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>571244.0</td>\n",
       "      <td>53800.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_amnt  int_rate  installment  grade  emp_length  home_ownership  \\\n",
       "0      18600     10.99       608.86      1           6               5   \n",
       "1       2000     17.97        72.28      3           4               1   \n",
       "2      12000     12.29       400.24      2           1               4   \n",
       "3      16000     19.42       589.90      3           7               5   \n",
       "4      22525     16.02       548.01      2           1               1   \n",
       "\n",
       "   annual_inc    dti  delinq_2yrs  inq_last_6mths  ...  total_rec_prncp  \\\n",
       "0     80000.0  12.92          0.0             0.0  ...          18600.0   \n",
       "1     55400.0  10.62          1.0             2.0  ...            128.9   \n",
       "2     60000.0  17.92          0.0             0.0  ...          12000.0   \n",
       "3     64000.0   3.90          1.0             0.0  ...           3561.4   \n",
       "4     94080.0  19.08          1.0             0.0  ...          22525.0   \n",
       "\n",
       "   total_rec_int  total_rec_late_fee  recoveries  collection_recovery_fee  \\\n",
       "0        1355.75                 0.0         0.0                      0.0   \n",
       "1          83.95                 0.0         0.0                      0.0   \n",
       "2         485.96                 0.0         0.0                      0.0   \n",
       "3        2303.08                 0.0         0.0                      0.0   \n",
       "4        2226.12                 0.0         0.0                      0.0   \n",
       "\n",
       "   last_pymnt_amnt  application_type  acc_now_delinq  tot_cur_bal  \\\n",
       "0         15705.09                 0             0.0     170238.0   \n",
       "1            72.28                 1             0.0     351452.0   \n",
       "2         11281.15                 0             0.0      18207.0   \n",
       "3           589.90                 0             0.0      12293.0   \n",
       "4         21483.11                 0             0.0     571244.0   \n",
       "\n",
       "   total_rev_hi_lim  \n",
       "0           20700.0  \n",
       "1           10800.0  \n",
       "2           20600.0  \n",
       "3            7800.0  \n",
       "4           53800.0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ddd9cf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data (using the same scaler)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed1e574",
   "metadata": {},
   "source": [
    "Fitting Linear Regression Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3a9f6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error for training data: 0.06683831179359304\n",
      "Mean Squared Error for testing data: 0.0676844931715756\n"
     ]
    }
   ],
   "source": [
    "# Fit linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions on training data\n",
    "y_pred_train = model.predict(X_train_scaled)\n",
    "mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "print(\"Mean Squared Error for training data:\", mse_train)\n",
    "\n",
    "\n",
    "# Predictions on test data\n",
    "\n",
    "y_pred_test = model.predict(X_test_scaled)\n",
    "mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "print(\"Mean Squared Error for testing data:\", mse_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd551a8",
   "metadata": {},
   "source": [
    "Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ccae7783",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "\n",
    "# Define the pipeline including any preprocessing steps\n",
    "# Replace 'preprocessing_step' with your actual preprocessing steps\n",
    "lasso_pipeline = Pipeline([\n",
    "    ('lasso', Lasso())  # Lasso regression model\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "653dd5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the alpha values to search over\n",
    "alphas = np.arange(0.01, 100, 0.01)\n",
    "\n",
    "# Define the hyperparameter distributions to search over\n",
    "param_distributions = {\n",
    "    'lasso__alpha': alphas  # Lasso alpha (regularization parameter) values\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b777b2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create RandomizedSearchCV object\n",
    "random_search_lasso = RandomizedSearchCV(\n",
    "    lasso_pipeline,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=len(alphas),  # Number of iterations is equal to the number of alpha values\n",
    "    cv=5,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    return_train_score=True,\n",
    "    n_jobs=-1,  # Use all available cores\n",
    "    random_state=69\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687e09d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a137b965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=Pipeline(steps=[(&#x27;lasso&#x27;, Lasso())]),\n",
       "                   n_iter=9999, n_jobs=-1,\n",
       "                   param_distributions={&#x27;lasso__alpha&#x27;: array([1.000e-02, 2.000e-02, 3.000e-02, ..., 9.997e+01, 9.998e+01,\n",
       "       9.999e+01])},\n",
       "                   random_state=69, return_train_score=True,\n",
       "                   scoring=&#x27;neg_mean_squared_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=Pipeline(steps=[(&#x27;lasso&#x27;, Lasso())]),\n",
       "                   n_iter=9999, n_jobs=-1,\n",
       "                   param_distributions={&#x27;lasso__alpha&#x27;: array([1.000e-02, 2.000e-02, 3.000e-02, ..., 9.997e+01, 9.998e+01,\n",
       "       9.999e+01])},\n",
       "                   random_state=69, return_train_score=True,\n",
       "                   scoring=&#x27;neg_mean_squared_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;lasso&#x27;, Lasso())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Lasso</label><div class=\"sk-toggleable__content\"><pre>Lasso()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=Pipeline(steps=[('lasso', Lasso())]),\n",
       "                   n_iter=9999, n_jobs=-1,\n",
       "                   param_distributions={'lasso__alpha': array([1.000e-02, 2.000e-02, 3.000e-02, ..., 9.997e+01, 9.998e+01,\n",
       "       9.999e+01])},\n",
       "                   random_state=69, return_train_score=True,\n",
       "                   scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the RandomizedSearchCV object to the training data\n",
    "random_search_lasso.fit(X_train_scaled, y_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4a2dfb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha is : 0.01\n"
     ]
    }
   ],
   "source": [
    "best_alpha = random_search_lasso.best_params_['lasso__alpha']\n",
    "print(\"Best alpha is :\", best_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b411e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error Train (Lasso): 0.06847457554349384\n",
      "Mean Squared Error Test (Lasso): 0.06939927625564418\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test data\n",
    "predictions_test = random_search_lasso.predict(X_test_scaled)\n",
    "predictions_train = random_search_lasso.predict(X_train_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "# Example: Calculate mean squared error\n",
    "mse_test = mean_squared_error(y_test, predictions_test)\n",
    "mse_train= mean_squared_error(y_train,predictions_train)\n",
    "print(\"Mean Squared Error Train (Lasso):\", mse_train)\n",
    "print(\"Mean Squared Error Test (Lasso):\", mse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8c220a",
   "metadata": {},
   "source": [
    "Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "efaf9f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Define the pipeline including any preprocessing steps\n",
    "# Replace 'preprocessing_step' with your actual preprocessing steps\n",
    "ridge_pipeline = Pipeline([\n",
    "    ('ridge', Ridge())  # Ridge regression model\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d1f00dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the alpha values to search over\n",
    "alphas = np.arange(0.01, 100, 0.01)\n",
    "\n",
    "# Define the hyperparameter distributions to search over\n",
    "param_distributions = {\n",
    "    'ridge__alpha': alphas  # Ridge alpha (regularization parameter) values\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "164cd35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "random_search_ridge = RandomizedSearchCV(\n",
    "    ridge_pipeline,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=len(alphas),  # Number of iterations is equal to the number of alpha values\n",
    "    cv=5,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    return_train_score=True,\n",
    "    n_jobs=-1,  # Use all available cores\n",
    "    random_state=69\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ba1b30e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fit the RandomizedSearchCV object to the training data\n",
    "random_search_ridge.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Extract the best alpha\n",
    "best_alpha_ridge = random_search_ridge.best_params_['ridge__alpha']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ce04abac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.99000000000001\n"
     ]
    }
   ],
   "source": [
    "print(best_alpha_ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6638af13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error Train (Ridge): 0.0668391362678708\n",
      "Mean Squared Error Test (Ridge): 0.06768778229021302\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test data\n",
    "predictions_test = random_search_ridge.predict(X_test_scaled)\n",
    "predictions_train = random_search_ridge.predict(X_train_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "# Calculate mean squared error\n",
    "mse_test = mean_squared_error(y_test, predictions_test)\n",
    "mse_train= mean_squared_error(y_train,predictions_train)\n",
    "print(\"Mean Squared Error Train (Ridge):\", mse_train)\n",
    "print(\"Mean Squared Error Test (Ridge):\", mse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096370f9",
   "metadata": {},
   "source": [
    "RANDOM FOREST CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a1bd475e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the parameter grid to search\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 150,200,250],\n",
    "    'max_depth': [3,5,10]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1907be44",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Instantiate the RandomForestClassifier\n",
    "clf = RandomForestClassifier(\n",
    "    random_state=69,\n",
    "    class_weight='balanced'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6437431a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Instantiate the GridSearchCV object\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=5, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "99a48384",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Perform the grid search on the tuning subset\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bdf463a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print (best_params['n_estimators'])\n",
    "print (best_params['max_depth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e2d18c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Instantiate the RandomForestClassifier with the best parameters\n",
    "best_clf = RandomForestClassifier(\n",
    "    n_estimators=best_params['n_estimators'],\n",
    "    max_depth=best_params['max_depth'],\n",
    "    random_state=69,\n",
    "    class_weight='balanced'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d8db0597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, max_depth=3, n_estimators=50,\n",
       "                       random_state=69)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, max_depth=3, n_estimators=50,\n",
       "                       random_state=69)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', max_depth=3, n_estimators=50,\n",
       "                       random_state=69)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Fit the classifier with the best parameters to the remaining training data\n",
    "best_clf.fit(X_train_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4bfb6864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': 3, 'n_estimators': 50}\n",
      "Training accuracy: 0.9623016962178185\n",
      "Test accuracy: 0.9607991953182151\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# Make predictions on the training and test data\n",
    "y_train_pred = best_clf.predict(X_train_scaled)\n",
    "y_test_pred = best_clf.predict(X_test_scaled)\n",
    "\n",
    "# Calculate accuracy and precision for training data\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "\n",
    "\n",
    "# Calculate accuracy and precision for test data\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "\n",
    "# Print the results\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Training accuracy:\", train_accuracy)\n",
    "\n",
    "print(\"Test accuracy:\", test_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4e86cbe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MSE: 0.03769830378218148\n",
      "Test MSE: 0.03920080468178493\n"
     ]
    }
   ],
   "source": [
    "#Calculate MSE for training and test data\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "print(\"Training MSE:\", train_mse)\n",
    "print(\"Test MSE:\", test_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "74b4374e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature 20 (0.363718) - recoveries\n",
      "2. feature 21 (0.306790) - collection_recovery_fee\n",
      "3. feature 22 (0.127809) - last_pymnt_amnt\n",
      "4. feature 17 (0.070668) - total_rec_prncp\n",
      "5. feature 3 (0.050194) - grade\n",
      "6. feature 1 (0.027419) - int_rate\n",
      "7. feature 19 (0.018079) - total_rec_late_fee\n",
      "8. feature 16 (0.016292) - total_pymnt_inv\n",
      "9. feature 15 (0.007410) - total_pymnt\n",
      "10. feature 2 (0.002291) - installment\n",
      "11. feature 26 (0.001998) - total_rev_hi_lim\n",
      "12. feature 9 (0.001647) - inq_last_6mths\n",
      "13. feature 18 (0.001594) - total_rec_int\n",
      "14. feature 7 (0.001567) - dti\n",
      "15. feature 0 (0.001197) - loan_amnt\n",
      "16. feature 23 (0.000431) - application_type\n",
      "17. feature 13 (0.000334) - revol_util\n",
      "18. feature 14 (0.000282) - total_acc\n",
      "19. feature 6 (0.000138) - annual_inc\n",
      "20. feature 5 (0.000138) - home_ownership\n",
      "21. feature 12 (0.000004) - revol_bal\n",
      "22. feature 11 (0.000000) - pub_rec\n",
      "23. feature 10 (0.000000) - open_acc\n",
      "24. feature 8 (0.000000) - delinq_2yrs\n",
      "25. feature 25 (0.000000) - tot_cur_bal\n",
      "26. feature 4 (0.000000) - emp_length\n",
      "27. feature 24 (0.000000) - acc_now_delinq\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1cAAAIhCAYAAACizkCYAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAABX5UlEQVR4nO3deVxV1f7/8fcRBBQFxQEkFVFzHlIwBcWhATUzzbpSFmra4M1SpLxlaqndxCxNM4cckrRS7GplZRmVOVzJFMEsvWZpYQaOCY7IsH9/+PN8PUxycB+O4Ov5eJxHslhnfdaCM/Bu77O2xTAMQwAAAACAa1LB2RMAAAAAgPKAcAUAAAAAJiBcAQAAAIAJCFcAAAAAYALCFQAAAACYgHAFAAAAACYgXAEAAACACQhXAAAAAGACwhUAAAAAmIBwBQDlSGxsrCwWS4G3Z5991iE19+zZo0mTJun33393yPjX4vfff5fFYlFsbKyzp1Ji69at06RJk5w9DQBAMbg6ewIAAPMtXbpUzZo1s2nz9/d3SK09e/Zo8uTJ6t69uxo0aOCQGiVVp04dJSQkqFGjRs6eSomtW7dOc+fOJWABQBlAuAKAcqhVq1YKDg529jSuSVZWliwWi1xdS/5W5e7urk6dOpk4q9Jz7tw5Va5c2dnTAADYgdMCAeAGFBcXp5CQEHl6eqpKlSrq2bOnkpKSbPrs2LFDDzzwgBo0aKBKlSqpQYMGevDBB/XHH39Y+8TGxuof//iHJKlHjx7WUxAvn4bXoEEDDR06NF/97t27q3v37tavv/vuO1ksFi1fvlzPPPOMbrrpJrm7u+vXX3+VJH399de6/fbb5eXlpcqVK6tz58765ptvrrrOgk4LnDRpkiwWi3788Uf94x//kLe3t3x8fBQdHa3s7Gzt27dPvXr1UtWqVdWgQQNNnz7dZszLc33vvfcUHR0tPz8/VapUSd26dcv3M5SktWvXKiQkRJUrV1bVqlV15513KiEhwabP5Tnt3LlT999/v6pXr65GjRpp6NChmjt3riTZnOJ5+RTMuXPnqmvXrqpdu7Y8PT3VunVrTZ8+XVlZWfl+3q1atdL27dsVFhamypUrq2HDhpo2bZpyc3Nt+p46dUrPPPOMGjZsKHd3d9WuXVt33XWX/ve//1n7XLx4Uf/+97/VrFkzubu7q1atWnrkkUd07Ngxm7G+/fZbde/eXTVq1FClSpVUv3593XfffTp37txVf3cAUBYRrgCgHMrJyVF2drbN7bKpU6fqwQcfVIsWLbRq1SotX75cp0+fVlhYmPbs2WPt9/vvv6tp06aaNWuW1q9fr1dffVWpqanq0KGDjh8/Lknq06ePpk6dKunSH/oJCQlKSEhQnz59SjTvcePGKSUlRQsWLNCnn36q2rVr67333lN4eLi8vLz07rvvatWqVfLx8VHPnj2LFbAKM3DgQLVt21arV6/WY489pjfeeENjxoxR//791adPH3300Ue67bbb9Nxzz2nNmjX57v/CCy/owIEDWrx4sRYvXqy//vpL3bt314EDB6x9PvjgA/Xr109eXl5asWKFlixZor///lvdu3fXli1b8o05YMAANW7cWB9++KEWLFigiRMn6v7775ck6882ISFBderUkST99ttvGjRokJYvX67PPvtMw4cP12uvvaYnnngi39hpaWl66KGH9PDDD2vt2rXq3bu3xo0bp/fee8/a5/Tp0+rSpYvefvttPfLII/r000+1YMECNWnSRKmpqZKk3Nxc9evXT9OmTdOgQYP0+eefa9q0aYqPj1f37t11/vx5SZceP3369JGbm5veeecdffnll5o2bZo8PT118eLFEv/eAOC6ZgAAyo2lS5cakgq8ZWVlGSkpKYarq6vx9NNP29zv9OnThp+fnzFw4MBCx87OzjbOnDljeHp6GrNnz7a2f/jhh4YkY8OGDfnuExAQYAwZMiRfe7du3Yxu3bpZv96wYYMhyejatatNv7Nnzxo+Pj5G3759bdpzcnKMtm3bGrfeemsRPw3DOHjwoCHJWLp0qbXtpZdeMiQZM2bMsOl7yy23GJKMNWvWWNuysrKMWrVqGQMGDMg31/bt2xu5ubnW9t9//92oWLGi8eijj1rn6O/vb7Ru3drIycmx9jt9+rRRu3ZtIzQ0NN+cXnzxxXxrGDlypFGct+ucnBwjKyvLWLZsmeHi4mKcPHnS+r1u3boZkoxt27bZ3KdFixZGz549rV9PmTLFkGTEx8cXWmfFihWGJGP16tU27du3bzckGfPmzTMMwzD+85//GJKM5OTkq84dAMoLjlwBQDm0bNkybd++3ebm6uqq9evXKzs7W4MHD7Y5quXh4aFu3brpu+++s45x5swZPffcc2rcuLFcXV3l6uqqKlWq6OzZs9q7d69D5n3ffffZfL1161adPHlSQ4YMsZlvbm6uevXqpe3bt+vs2bMlqnX33XfbfN28eXNZLBb17t3b2ubq6qrGjRvbnAp52aBBg2SxWKxfBwQEKDQ0VBs2bJAk7du3T3/99ZciIyNVocL/vd1WqVJF9913n77//vt8p8flXf/VJCUl6Z577lGNGjXk4uKiihUravDgwcrJydEvv/xi09fPz0+33nqrTVubNm1s1vbFF1+oSZMmuuOOOwqt+dlnn6latWrq27evze/klltukZ+fn/UxdMstt8jNzU2PP/643n33XZsjegBQXrGhBQCUQ82bNy9wQ4sjR45Ikjp06FDg/a4MAYMGDdI333yjiRMnqkOHDvLy8pLFYtFdd91lPfXLbJdPd8s738unxhXk5MmT8vT0tLuWj4+Pzddubm6qXLmyPDw88rVnZGTku7+fn1+Bbbt27ZIknThxQlL+NUmXdm7Mzc3V33//bbNpRUF9C5OSkqKwsDA1bdpUs2fPVoMGDeTh4aEffvhBI0eOzPc7qlGjRr4x3N3dbfodO3ZM9evXL7LukSNHdOrUKbm5uRX4/cunjDZq1Ehff/21pk+frpEjR+rs2bNq2LChRo0apdGjRxd7nQBQlhCuAOAGUrNmTUnSf/7zHwUEBBTaLz09XZ999pleeuklPf/889b2zMxMnTx5stj1PDw8lJmZma/9+PHj1rlc6cojQVfOd86cOYXu+ufr61vs+ZgpLS2twLbLIebyfy9/VulKf/31lypUqKDq1avbtOddf1E+/vhjnT17VmvWrLH5XSYnJxd7jLxq1aqlP//8s8g+NWvWVI0aNfTll18W+P2qVata/x0WFqawsDDl5ORox44dmjNnjqKiouTr66sHHnigxPMEgOsV4QoAbiA9e/aUq6urfvvttyJPQbNYLDIMQ+7u7jbtixcvVk5Ojk3b5T4FHc1q0KCBfvzxR5u2X375Rfv27SswXOXVuXNnVatWTXv27NFTTz111f6lacWKFYqOjrYGoj/++ENbt27V4MGDJUlNmzbVTTfdpA8++EDPPvustd/Zs2e1evVq6w6CV3Plz7dSpUrW9svjXfk7MgxDixYtKvGaevfurRdffFHffvutbrvttgL73H333Vq5cqVycnLUsWPHYo3r4uKijh07qlmzZnr//fe1c+dOwhWAcolwBQA3kAYNGmjKlCkaP368Dhw4oF69eql69eo6cuSIfvjhB3l6emry5Mny8vJS165d9dprr6lmzZpq0KCBNm7cqCVLlqhatWo2Y7Zq1UqStHDhQlWtWlUeHh4KDAxUjRo1FBkZqYcfflhPPvmk7rvvPv3xxx+aPn26atWqVaz5VqlSRXPmzNGQIUN08uRJ3X///apdu7aOHTumXbt26dixY5o/f77ZP6ZiOXr0qO6991499thjSk9P10svvSQPDw+NGzdO0qVTLKdPn66HHnpId999t5544gllZmbqtdde06lTpzRt2rRi1WndurUk6dVXX1Xv3r3l4uKiNm3a6M4775Sbm5sefPBB/etf/9KFCxc0f/58/f333yVeU1RUlOLi4tSvXz89//zzuvXWW3X+/Hlt3LhRd999t3r06KEHHnhA77//vu666y6NHj1at956qypWrKg///xTGzZsUL9+/XTvvfdqwYIF+vbbb9WnTx/Vr19fFy5c0DvvvCNJRX6mCwDKNGfvqAEAMM/l3QK3b99eZL+PP/7Y6NGjh+Hl5WW4u7sbAQEBxv333298/fXX1j5//vmncd999xnVq1c3qlatavTq1cv46aefCtwBcNasWUZgYKDh4uJisztfbm6uMX36dKNhw4aGh4eHERwcbHz77beF7hb44YcfFjjfjRs3Gn369DF8fHyMihUrGjfddJPRp0+fQvtfVtRugceOHbPpO2TIEMPT0zPfGN26dTNatmyZb67Lly83Ro0aZdSqVctwd3c3wsLCjB07duS7/8cff2x07NjR8PDwMDw9PY3bb7/d+O9//2vTp7A5GYZhZGZmGo8++qhRq1Ytw2KxGJKMgwcPGoZhGJ9++qnRtm1bw8PDw7jpppuMsWPHGl988UW+3RvzruHKNQcEBNi0/f3338bo0aON+vXrGxUrVjRq165t9OnTx/jf//5n7ZOVlWW8/vrr1tpVqlQxmjVrZjzxxBPG/v37DcMwjISEBOPee+81AgICDHd3d6NGjRpGt27djLVr1+abBwCUFxbDMAynJTsAAMqY7777Tj169NCHH35Y5EYbAIAbD1uxAwAAAIAJCFcAAAAAYAJOCwQAAAAAE3DkCgAAAABMQLgCAAAAABMQrgAAAADABFxEuAC5ubn666+/VLVqVVksFmdPBwAAAICTGIah06dPy9/fXxUqFH1sinBVgL/++kv16tVz9jQAAAAAXCcOHTqkunXrFtmHcFWAqlWrSrr0A/Ty8nLybAAAAAA4S0ZGhurVq2fNCEUhXBXg8qmAXl5ehCsAAAAAxfq4EBtaAAAAAIAJCFcAAAAAYALCFQAAAACYgHAFAAAAACYgXAEAAACACQhXAAAAAGACwhUAAAAAmIBwBQAAAAAmIFwBAAAAgAkIVwAAAABgAsIVAAAAAJiAcAUAAAAAJiBcAQAAAIAJCFcAAAAAYALCFQAAAACYgHAFAAAAACYgXAEAAACACQhXAAAAAGACwhUAAAAAmMDV2RMozywWx4xrGI4ZFwAAAEDJceQKAAAAAExAuAIAAAAAExCuAAAAAMAEhCsAAAAAMAHhCgAAAABMQLgCAAAAABMQrgAAAADABIQrAAAAADAB4QoAAAAATEC4AgAAAAATEK4AAAAAwAROD1fz5s1TYGCgPDw8FBQUpM2bNxfad8uWLercubNq1KihSpUqqVmzZnrjjTds+sTGxspiseS7XbhwwdFLAQAAAHADc3Vm8bi4OEVFRWnevHnq3Lmz3n77bfXu3Vt79uxR/fr18/X39PTUU089pTZt2sjT01NbtmzRE088IU9PTz3++OPWfl5eXtq3b5/NfT08PBy+HgAAAAA3LothGIazinfs2FHt27fX/PnzrW3NmzdX//79FRMTU6wxBgwYIE9PTy1fvlzSpSNXUVFROnXqVInnlZGRIW9vb6Wnp8vLy6vE41gsJb5rkZz3GwMAAABuLPZkA6edFnjx4kUlJiYqPDzcpj08PFxbt24t1hhJSUnaunWrunXrZtN+5swZBQQEqG7durr77ruVlJRU5DiZmZnKyMiwuQEAAACAPZwWro4fP66cnBz5+vratPv6+iotLa3I+9atW1fu7u4KDg7WyJEj9eijj1q/16xZM8XGxmrt2rVasWKFPDw81LlzZ+3fv7/Q8WJiYuTt7W291atX79oWBwAAAOCG49TPXEmSJc+5c4Zh5GvLa/PmzTpz5oy+//57Pf/882rcuLEefPBBSVKnTp3UqVMna9/OnTurffv2mjNnjt58880Cxxs3bpyio6OtX2dkZBCwAAAAANjFaeGqZs2acnFxyXeU6ujRo/mOZuUVGBgoSWrdurWOHDmiSZMmWcNVXhUqVFCHDh2KPHLl7u4ud3d3O1cAAAAAAP/HaacFurm5KSgoSPHx8Tbt8fHxCg0NLfY4hmEoMzOzyO8nJyerTp06JZ4rAAAAAFyNU08LjI6OVmRkpIKDgxUSEqKFCxcqJSVFI0aMkHTpdL3Dhw9r2bJlkqS5c+eqfv36atasmaRL1716/fXX9fTTT1vHnDx5sjp16qSbb75ZGRkZevPNN5WcnKy5c+eW/gIBAAAA3DCcGq4iIiJ04sQJTZkyRampqWrVqpXWrVungIAASVJqaqpSUlKs/XNzczVu3DgdPHhQrq6uatSokaZNm6YnnnjC2ufUqVN6/PHHlZaWJm9vb7Vr106bNm3SrbfeWurrAwAAAHDjcOp1rq5XXOcKAAAAgFRGrnMFAAAAAOUJ4QoAAAAATEC4AgAAAAATEK4AAAAAwASEKwAAAAAwAeEKAAAAAExAuAIAAAAAExCuAAAAAMAEhCsAAAAAMAHhCgAAAABMQLgCAAAAABMQrgAAAADABIQrAAAAADAB4QoAAAAATEC4AgAAAAATEK4AAAAAwASEKwAAAAAwAeEKAAAAAExAuAIAAAAAExCuAAAAAMAEhCsAAAAAMAHhCgAAAABMQLgCAAAAABMQrgAAAADABIQrAAAAADAB4QoAAAAATEC4AgAAAAATEK4AAAAAwASEKwAAAAAwAeEKAAAAAExAuAIAAAAAExCuAAAAAMAEhCsAAAAAMAHhCgAAAABMQLgCAAAAABMQrgAAAADABIQrAAAAADAB4QoAAAAATEC4AgAAAAATEK4AAAAAwASEKwAAAAAwAeEKAAAAAExAuAIAAAAAExCuAAAAAMAEhCsAAAAAMAHhCgAAAABM4OrsCcA8FotjxjUMx4wLAAAAlCccuQIAAAAAExCuAAAAAMAEhCsAAAAAMIHTw9W8efMUGBgoDw8PBQUFafPmzYX23bJlizp37qwaNWqoUqVKatasmd544418/VavXq0WLVrI3d1dLVq00EcffeTIJQAAAACAc8NVXFycoqKiNH78eCUlJSksLEy9e/dWSkpKgf09PT311FNPadOmTdq7d68mTJigCRMmaOHChdY+CQkJioiIUGRkpHbt2qXIyEgNHDhQ27ZtK61lAQAAALgBWQzDeXvBdezYUe3bt9f8+fOtbc2bN1f//v0VExNTrDEGDBggT09PLV++XJIUERGhjIwMffHFF9Y+vXr1UvXq1bVixYpijZmRkSFvb2+lp6fLy8vLjhXZKu3d+9gtEAAAADCXPdnAaUeuLl68qMTERIWHh9u0h4eHa+vWrcUaIykpSVu3blW3bt2sbQkJCfnG7NmzZ5FjZmZmKiMjw+YGAAAAAPZwWrg6fvy4cnJy5Ovra9Pu6+urtLS0Iu9bt25dubu7Kzg4WCNHjtSjjz5q/V5aWprdY8bExMjb29t6q1evXglWBAAAAOBG5vQNLSx5zmUzDCNfW16bN2/Wjh07tGDBAs2aNSvf6X72jjlu3Dilp6dbb4cOHbJzFQAAAABudK7OKlyzZk25uLjkO6J09OjRfEee8goMDJQktW7dWkeOHNGkSZP04IMPSpL8/PzsHtPd3V3u7u4lWQYAAAAASHLikSs3NzcFBQUpPj7epj0+Pl6hoaHFHscwDGVmZlq/DgkJyTfmV199ZdeYAAAAAGAvpx25kqTo6GhFRkYqODhYISEhWrhwoVJSUjRixAhJl07XO3z4sJYtWyZJmjt3rurXr69mzZpJunTdq9dff11PP/20dczRo0era9euevXVV9WvXz998skn+vrrr7Vly5bSXyAAAACAG4ZTw1VERIROnDihKVOmKDU1Va1atdK6desUEBAgSUpNTbW55lVubq7GjRungwcPytXVVY0aNdK0adP0xBNPWPuEhoZq5cqVmjBhgiZOnKhGjRopLi5OHTt2LPX1AQAAALhxOPU6V9crrnNVvHoAAABAeVcmrnMFAAAAAOUJ4QoAAAAATEC4AgAAAAATEK4AAAAAwASEKwAAAAAwAeEKAAAAAExAuAIAAAAAExCuAAAAAMAEhCsAAAAAMAHhCgAAAABMQLgCAAAAABMQrgAAAADABIQrAAAAADAB4QoAAAAATEC4AgAAAAATEK4AAAAAwASEKwAAAAAwAeEKAAAAAExAuAIAAAAAExCuAAAAAMAEhCsAAAAAMAHhCgAAAABMQLgCAAAAABMQrgAAAADABIQrAAAAADAB4QoAAAAATEC4AgAAAAATEK4AAAAAwASEKwAAAAAwAeEKAAAAAExAuAIAAAAAExCuAAAAAMAEhCsAAAAAMAHhCgAAAABMQLgCAAAAABMQrgAAAADABIQrAAAAADAB4QoAAAAATEC4AgAAAAATEK4AAAAAwASEKwAAAAAwAeEKAAAAAExAuAIAAAAAExCuAAAAAMAEhCsAAAAAMAHhCgAAAABMQLgCAAAAABMQrgAAAADABIQrAAAAADCB08PVvHnzFBgYKA8PDwUFBWnz5s2F9l2zZo3uvPNO1apVS15eXgoJCdH69ett+sTGxspiseS7XbhwwdFLAQAAAHADc2q4iouLU1RUlMaPH6+kpCSFhYWpd+/eSklJKbD/pk2bdOedd2rdunVKTExUjx491LdvXyUlJdn08/LyUmpqqs3Nw8OjNJYEAAAA4AZlMQzDcFbxjh07qn379po/f761rXnz5urfv79iYmKKNUbLli0VERGhF198UdKlI1dRUVE6depUieeVkZEhb29vpaeny8vLq8TjWCwlvmuRCvuNlXY9AAAAoLyzJxs47cjVxYsXlZiYqPDwcJv28PBwbd26tVhj5Obm6vTp0/Lx8bFpP3PmjAICAlS3bl3dfffd+Y5s5ZWZmamMjAybGwAAAADYw2nh6vjx48rJyZGvr69Nu6+vr9LS0oo1xowZM3T27FkNHDjQ2tasWTPFxsZq7dq1WrFihTw8PNS5c2ft37+/0HFiYmLk7e1tvdWrV69kiwIAAABww3L6hhaWPOeyGYaRr60gK1as0KRJkxQXF6fatWtb2zt16qSHH35Ybdu2VVhYmFatWqUmTZpozpw5hY41btw4paenW2+HDh0q+YIAAAAA3JBcnVW4Zs2acnFxyXeU6ujRo/mOZuUVFxen4cOH68MPP9Qdd9xRZN8KFSqoQ4cORR65cnd3l7u7e/EnDwAAAAB5OO3IlZubm4KCghQfH2/THh8fr9DQ0ELvt2LFCg0dOlQffPCB+vTpc9U6hmEoOTlZderUueY5AwAAAEBhnHbkSpKio6MVGRmp4OBghYSEaOHChUpJSdGIESMkXTpd7/Dhw1q2bJmkS8Fq8ODBmj17tjp16mQ96lWpUiV5e3tLkiZPnqxOnTrp5ptvVkZGht58800lJydr7ty5zlkkAAAAgBuCU8NVRESETpw4oSlTpig1NVWtWrXSunXrFBAQIElKTU21uebV22+/rezsbI0cOVIjR460tg8ZMkSxsbGSpFOnTunxxx9XWlqavL291a5dO23atEm33nprqa4NAAAAwI2lRNe52rx5s95++2399ttv+s9//qObbrpJy5cvV2BgoLp06eKIeZYqrnNVvHoAAABAeefQ61ytXr1aPXv2VKVKlZSUlKTMzExJ0unTpzV16tSSzRgAAAAAyji7w9W///1vLViwQIsWLVLFihWt7aGhodq5c6epkwMAAACAssLucLVv3z517do1X7uXl5dOnTplxpwAAAAAoMyxO1zVqVNHv/76a772LVu2qGHDhqZMCgAAAADKGrvD1RNPPKHRo0dr27Ztslgs+uuvv/T+++/r2Wef1ZNPPumIOQIAAADAdc/urdj/9a9/KT09XT169NCFCxfUtWtXubu769lnn9VTTz3liDkCAAAAwHWvRFuxS9K5c+e0Z88e5ebmqkWLFqpSpYrZc3MatmIvXj0AAACgvLMnG9h95Co9PV05OTny8fFRcHCwtf3kyZNydXW9pjACAAAAAGWV3Z+5euCBB7Ry5cp87atWrdIDDzxgyqQAAAAAoKyxO1xt27ZNPXr0yNfevXt3bdu2zZRJAQAAAEBZY3e4yszMVHZ2dr72rKwsnT9/3pRJAQAAAEBZY3e46tChgxYuXJivfcGCBQoKCjJlUgAAAABQ1ti9ocUrr7yiO+64Q7t27dLtt98uSfrmm2+0fft2ffXVV6ZPEAAAAADKAruPXHXu3FkJCQmqV6+eVq1apU8//VSNGzfWjz/+qLCwMEfMEQAAAACueyW+zlV5xnWuilcPAAAAKO8cep0rScrNzdWvv/6qo0ePKjc31+Z7Xbt2LcmQAAAAAFCm2R2uvv/+ew0aNEh//PGH8h70slgsysnJMW1yAAAAAFBW2B2uRowYoeDgYH3++eeqU6eOLI46Fw0AAAAAyhC7w9X+/fv1n//8R40bN3bEfAAAAACgTLJ7t8COHTvq119/dcRcAAAAAKDMsvvI1dNPP61nnnlGaWlpat26tSpWrGjz/TZt2pg2OQAAAAAoK+zeir1ChfwHuywWiwzDKDcbWrAVe/HqAQAAAOWdQ7diP3jwYIknBgAAAADlld3hKiAgwBHzAAAAAIAyrUQXEZakPXv2KCUlRRcvXrRpv+eee655UgAAAABQ1tgdrg4cOKB7771Xu3fvtn7WSpL1elfl4TNXAAAAAGAvu7diHz16tAIDA3XkyBFVrlxZP//8szZt2qTg4GB99913DpgiAAAAAFz/7D5ylZCQoG+//Va1atVShQoVVKFCBXXp0kUxMTEaNWqUkpKSHDFPAAAAALiu2X3kKicnR1WqVJEk1axZU3/99ZekSxtd7Nu3z9zZAQAAAEAZYfeRq1atWunHH39Uw4YN1bFjR02fPl1ubm5auHChGjZs6Ig5AgAAAMB1z+5wNWHCBJ09e1aS9O9//1t33323wsLCVKNGDa1cudL0CQIAAABAWWAxLm/3dw1Onjyp6tWrW3cMLOvsuQpzURz14yjsN1ba9QAAAIDyzp5sYPdnroYNG6bTp0/btPn4+OjcuXMaNmyYvcMBAAAAQLlgd7h69913df78+Xzt58+f17Jly0yZFAAAAACUNcX+zFVGRoYMw5BhGDp9+rQ8PDys38vJydG6detUu3Zth0wSAAAAAK53xQ5X1apVk8VikcViUZMmTfJ932KxaPLkyaZODgAAAADKimKHqw0bNsgwDN12221avXq1fHx8rN9zc3NTQECA/P39HTJJAAAAALjeFTtcdevWTdnZ2Ro8eLCCg4NVr149R84LAAAAAMoUuza0cHV11erVq5WTk+Oo+QAAAABAmWT3boG33367vvvuOwdMBQAAAADKrmKfFnhZ7969NW7cOP30008KCgqSp6enzffvuece0yYHAAAAAGWFxTAMw547VKhQ+MEui8VSLk4ZtOcqzEWxWEyc1BUK+42Vdj0AAACgvLMnG9h95Co3N7fEEwMAAACA8sruz1wBAAAAAPIrUbjauHGj+vbtq8aNG+vmm2/WPffco82bN5s9NwAAAAAoM+wOV++9957uuOMOVa5cWaNGjdJTTz2lSpUq6fbbb9cHH3zgiDkCAAAAwHXP7g0tmjdvrscff1xjxoyxaZ85c6YWLVqkvXv3mjpBZ2BDi+LVAwAAAMo7e7KB3UeuDhw4oL59++Zrv+eee3Tw4EF7hwMAAACAcsHucFWvXj198803+dq/+eYb1atXz5RJAQAAAEBZY/dW7M8884xGjRql5ORkhYaGymKxaMuWLYqNjdXs2bMdMUcAAAAAuO7ZfeTqn//8p1auXKndu3crKipKo0eP1k8//aS4uDg98cQTdk9g3rx5CgwMlIeHh4KCgorcdXDNmjW68847VatWLXl5eSkkJETr16/P12/16tVq0aKF3N3d1aJFC3300Ud2zwsAAAAA7FGirdjvvfdebdmyRSdOnNCJEye0ZcsW9evXz+5x4uLiFBUVpfHjxyspKUlhYWHq3bu3UlJSCuy/adMm3XnnnVq3bp0SExPVo0cP9e3bV0lJSdY+CQkJioiIUGRkpHbt2qXIyEgNHDhQ27ZtK8lSAQAAAKBY7N4t8LIdO3Zo7969slgsat68uYKCguweo2PHjmrfvr3mz59vbWvevLn69++vmJiYYo3RsmVLRURE6MUXX5QkRUREKCMjQ1988YW1T69evVS9enWtWLGiWGOyW2Dx6gEAAADlnT3ZwO7PXP3555968MEH9d///lfVqlWTJJ06dUqhoaFasWJFsTe1uHjxohITE/X888/btIeHh2vr1q3FGiM3N1enT5+Wj4+PtS0hISHfNvE9e/bUrFmzCh0nMzNTmZmZ1q8zMjKKVR8AAAAALrP7tMBhw4YpKytLe/fu1cmTJ3Xy5Ent3btXhmFo+PDhxR7n+PHjysnJka+vr027r6+v0tLSijXGjBkzdPbsWQ0cONDalpaWZveYMTEx8vb2tt7Y9RAAAACAvewOV5s3b9b8+fPVtGlTa1vTpk01Z86cIjejKIwlz7lshmHkayvIihUrNGnSJMXFxal27drXNOa4ceOUnp5uvR06dMiOFQAAAABACU4LrF+/vrKysvK1Z2dn66abbir2ODVr1pSLi0u+I0pHjx7Nd+Qpr7i4OA0fPlwffvih7rjjDpvv+fn52T2mu7u73N3diz13AAAAAMjL7iNX06dP19NPP60dO3bo8l4YO3bs0OjRo/X6668Xexw3NzcFBQUpPj7epj0+Pl6hoaGF3m/FihUaOnSoPvjgA/Xp0yff90NCQvKN+dVXXxU5JgAAAABcK7t3C6xevbrOnTun7OxsubpeOvB1+d+enp42fU+ePFnkWHFxcYqMjNSCBQsUEhKihQsXatGiRfr5558VEBCgcePG6fDhw1q2bJmkS8Fq8ODBmj17tgYMGGAdp1KlSvL29pYkbd26VV27dtUrr7yifv366ZNPPtGECRO0ZcsWdezYsVhrZLfA4tUDAAAAyjuH7hZY1K579oqIiNCJEyc0ZcoUpaamqlWrVlq3bp0CAgIkSampqTbXvHr77beVnZ2tkSNHauTIkdb2IUOGKDY2VpIUGhqqlStXasKECZo4caIaNWqkuLi4YgcrAAAAACiJEl/nqjzjyFXx6gEAAADlnUOPXF129OhRHT16VLm5uTbtbdq0KemQAAAAAFBm2R2uEhMTNWTIEOu1ra5ksViUk5Nj2uQAAAAAoKywO1w98sgjatKkiZYsWSJfX99iXZMKAAAAAMo7u8PVwYMHtWbNGjVu3NgR8wEAAACAMsnu61zdfvvt2rVrlyPmAgAAAABllt1HrhYvXqwhQ4bop59+UqtWrVSxYkWb799zzz2mTQ4AAAAAygq7w9XWrVu1ZcsWffHFF/m+x4YWAAAAAG5Udp8WOGrUKEVGRio1NVW5ubk2N4IVAAAAgBuV3eHqxIkTGjNmjHx9fR0xHwAAAAAok+wOVwMGDNCGDRscMRcAAAAAKLPs/sxVkyZNNG7cOG3ZskWtW7fOt6HFqFGjTJscAAAAAJQVFsMwDHvuEBgYWPhgFosOHDhwzZNytoyMDHl7eys9PV1eXl4lHsdR11cu7DdW2vUAAACA8s6ebFCiiwgDAAAAAGzZ/ZkrAAAAAEB+xTpyFR0drZdfflmenp6Kjo4usu/MmTNNmRgAAAAAlCXFCldJSUnKysqy/rswFkd96AcAAAAArnN2b2hxI2BDi+LVAwAAAMo7e7IBn7kCAAAAABMQrgAAAADABIQrAAAAADAB4QoAAAAATEC4AgAAAAATlChcLV++XJ07d5a/v7/++OMPSdKsWbP0ySefmDo5AAAAACgr7A5X8+fPV3R0tO666y6dOnVKOTk5kqRq1app1qxZZs8PAAAAAMoEu8PVnDlztGjRIo0fP14uLi7W9uDgYO3evdvUyQEAAABAWWF3uDp48KDatWuXr93d3V1nz541ZVIAAAAAUNbYHa4CAwOVnJycr/2LL75QixYtzJgTAAAAAJQ5rvbeYezYsRo5cqQuXLggwzD0ww8/aMWKFYqJidHixYsdMUcAAAAAuO7ZHa4eeeQRZWdn61//+pfOnTunQYMG6aabbtLs2bP1wAMPOGKOAAAAAHDdsytcZWdn6/3331ffvn312GOP6fjx48rNzVXt2rUdNT8AAAAAKBPs+syVq6ur/vnPfyozM1OSVLNmTYIVAAAAAKgEG1p07NhRSUlJjpgLAAAAAJRZdn/m6sknn9QzzzyjP//8U0FBQfL09LT5fps2bUybHAAAAACUFRbDMAx77lChQv6DXRaLRYZhyGKxKCcnx7TJOUtGRoa8vb2Vnp4uLy+vEo9jsZg4qSsU9hsr7XoAAABAeWdPNrD7yNXBgwdLPDEAAAAAKK/sDlcBAQGOmAcAAAAAlGl2h6tly5YV+f3BgweXeDIAAAAAUFbZ/Zmr6tWr23ydlZWlc+fOyc3NTZUrV9bJkydNnaAz8Jmr4tUDAAAAyjt7soHdW7H//fffNrczZ85o37596tKli1asWFHiSQMAAABAWWZ3uCrIzTffrGnTpmn06NFmDAcAAAAAZY4p4UqSXFxc9Ndff5k1HAAAAACUKXZvaLF27Vqbrw3DUGpqqt566y117tzZtIkBAAAAQFlid7jq37+/zdcWi0W1atXSbbfdphkzZpg1LwAAAAAoU+wOV7m5uY6YBwAAAACUaXZ/5mrKlCk6d+5cvvbz589rypQppkwKAAAAAMoau69z5eLiotTUVNWuXdum/cSJE6pdu7ZycnJMnaAzcJ2r4tUDAAAAyjuHXufKMAxZCvgrfteuXfLx8bF3OAAAAAAoF4r9mavq1avLYrHIYrGoSZMmNgErJydHZ86c0YgRIxwySQAAAAC43hU7XM2aNUuGYWjYsGGaPHmyvL29rd9zc3NTgwYNFBIS4pBJAgAAAMD1rtjhasiQIZKkwMBAhYaGqmLFiqZMYN68eXrttdeUmpqqli1batasWQoLCyuwb2pqqp555hklJiZq//79GjVqlGbNmmXTJzY2Vo888ki++54/f14eHh6mzBkAAAAA8rL7M1fdunWzBqvz588rIyPD5maPuLg4RUVFafz48UpKSlJYWJh69+6tlJSUAvtnZmaqVq1aGj9+vNq2bVvouF5eXkpNTbW5EawAAAAAOJLd4ercuXN66qmnVLt2bVWpUkXVq1e3udlj5syZGj58uB599FE1b95cs2bNUr169TR//vwC+zdo0ECzZ8/W4MGDbU5LzMtiscjPz8/mBgAAAACOZHe4Gjt2rL799lvNmzdP7u7uWrx4sSZPnix/f38tW7as2ONcvHhRiYmJCg8Pt2kPDw/X1q1b7Z2WjTNnziggIEB169bV3XffraSkpCL7Z2ZmXtMROAAAAACwO1x9+umnmjdvnu6//365uroqLCxMEyZM0NSpU/X+++8Xe5zjx48rJydHvr6+Nu2+vr5KS0uzd1pWzZo1U2xsrNauXasVK1bIw8NDnTt31v79+wu9T0xMjLy9va23evXqlbg+AAAAgBuT3eHq5MmTCgwMlHTps00nT56UJHXp0kWbNm2yewJ5r5lV2HW0iqtTp056+OGH1bZtW4WFhWnVqlVq0qSJ5syZU+h9xo0bp/T0dOvt0KFDJa4PAAAA4MZkd7hq2LChfv/9d0lSixYttGrVKkmXjmhVq1at2OPUrFlTLi4u+Y5SHT16NN/RrGtRoUIFdejQocgjV+7u7vLy8rK5AQAAAIA97A5XjzzyiHbt2iXp0hGfy5+9GjNmjMaOHVvscdzc3BQUFKT4+Hib9vj4eIWGhto7rUIZhqHk5GTVqVPHtDEBAAAAIK9iX+fqsjFjxlj/3aNHD/3vf//Tjh071KhRoyK3Ry9IdHS0IiMjFRwcrJCQEC1cuFApKSkaMWKEpEvh7fDhwzYbZSQnJ0u6tGnFsWPHlJycLDc3N7Vo0UKSNHnyZHXq1Ek333yzMjIy9Oabbyo5OVlz5861d6kAAAAAUGx2h6srXbhwQfXr11f9+vVLdP+IiAidOHFCU6ZMUWpqqlq1aqV169YpICBA0qWLBue95lW7du2s/05MTNQHH3yggIAA66mKp06d0uOPP660tDR5e3urXbt22rRpk2699daSLRIAAAAAisFiGIZhzx1ycnI0depULViwQEeOHNEvv/yihg0bauLEiWrQoIGGDx/uqLmWmoyMDHl7eys9Pf2aPn91DftyFKmw31hp1wMAAADKO3uygd2fuXrllVcUGxur6dOny83NzdreunVrLV682P7ZAgAAAEA5YHe4WrZsmRYuXKiHHnpILi4u1vY2bdrof//7n6mTAwAAAICywu5wdfjwYTVu3Dhfe25urrKyskyZFAAAAACUNXaHq5YtW2rz5s352j/88EObzSYAAAAA4EZi926BL730kiIjI3X48GHl5uZqzZo12rdvn5YtW6bPPvvMEXMEAAAAgOue3Ueu+vbtq7i4OK1bt04Wi0Uvvvii9u7dq08//VR33nmnI+YIAAAAANe9Ym/FfuDAAQUGBsriqP2+ryNsxV68egAAAEB555Ct2G+++WYdO3bM+nVERISOHDlS8lkCAAAAQDlS7HCV9wDXunXrdPbsWdMnBAAAAABlkd2fuQIAAAAA5FfscGWxWPJ93upG+PwVAAAAABRHsbdiNwxDQ4cOlbu7uyTpwoULGjFihDw9PW36rVmzxtwZAgAAAEAZUOxwNWTIEJuvH374YdMnAwAAAABlVbHD1dKlSx05DwAAAAAo09jQAgAAAABMQLgCAAAAABMQrgAAAADABIQrAAAAADAB4QoAAAAATEC4AgAAAAATFHsrduBKFotjxjUMx4wLAAAAOBpHrgAAAADABIQrAAAAADAB4QoAAAAATEC4AgAAAAATEK4AAAAAwASEKwAAAAAwAeEKAAAAAExAuAIAAAAAExCuAAAAAMAEhCsAAAAAMAHhCgAAAABMQLgCAAAAABMQrgAAAADABIQrAAAAADAB4QoAAAAATEC4AgAAAAATEK4AAAAAwASEKwAAAAAwAeEKAAAAAExAuAIAAAAAExCuAAAAAMAEhCsAAAAAMAHhCgAAAABMQLgCAAAAABMQrgAAAADABIQrAAAAADAB4QoAAAAATEC4AgAAAAATEK4AAAAAwAROD1fz5s1TYGCgPDw8FBQUpM2bNxfaNzU1VYMGDVLTpk1VoUIFRUVFFdhv9erVatGihdzd3dWiRQt99NFHDpo9AAAAAFzi1HAVFxenqKgojR8/XklJSQoLC1Pv3r2VkpJSYP/MzEzVqlVL48ePV9u2bQvsk5CQoIiICEVGRmrXrl2KjIzUwIEDtW3bNkcuBQAAAMANzmIYhuGs4h07dlT79u01f/58a1vz5s3Vv39/xcTEFHnf7t2765ZbbtGsWbNs2iMiIpSRkaEvvvjC2tarVy9Vr15dK1asKNa8MjIy5O3trfT0dHl5eRV/QXlYLCW+a5EK+42VZr3SXhsAAADgDPZkA6cdubp48aISExMVHh5u0x4eHq6tW7eWeNyEhIR8Y/bs2bPIMTMzM5WRkWFzAwAAAAB7OC1cHT9+XDk5OfL19bVp9/X1VVpaWonHTUtLs3vMmJgYeXt7W2/16tUrcX0AAAAANyanb2hhyXN+mWEY+docPea4ceOUnp5uvR06dOia6gMAAAC48bg6q3DNmjXl4uKS74jS0aNH8x15soefn5/dY7q7u8vd3b3ENQEAAADAaUeu3NzcFBQUpPj4eJv2+Ph4hYaGlnjckJCQfGN+9dVX1zQmAAAAAFyN045cSVJ0dLQiIyMVHByskJAQLVy4UCkpKRoxYoSkS6frHT58WMuWLbPeJzk5WZJ05swZHTt2TMnJyXJzc1OLFi0kSaNHj1bXrl316quvql+/fvrkk0/09ddfa8uWLaW+PgAAAAA3DqeGq4iICJ04cUJTpkxRamqqWrVqpXXr1ikgIEDSpYsG573mVbt27az/TkxM1AcffKCAgAD9/vvvkqTQ0FCtXLlSEyZM0MSJE9WoUSPFxcWpY8eOpbYuAAAAADcep17n6nrFda6uXo/rXAEAAOBGUCaucwUAAAAA5QnhCgAAAABMQLgCAAAAABMQrgAAAADABIQrAAAAADAB4QoAAAAATEC4AgAAAAATEK4AAAAAwASEKwAAAAAwAeEKAAAAAExAuAIAAAAAExCuAAAAAMAEhCsAAAAAMAHhCgAAAABMQLgCAAAAABMQrgAAAADABIQrAAAAADAB4QoAAAAATEC4AgAAAAATEK4AAAAAwASEKwAAAAAwAeEKAAAAAExAuAIAAAAAExCuAAAAAMAEhCsAAAAAMAHhCgAAAABMQLgCAAAAABMQrgAAAADABK7OngBQHBaLY8Y1DMeMCwAAgBsPR64AAAAAwASEKwAAAAAwAeEKAAAAAExAuAIAAAAAExCuAAAAAMAEhCsAAAAAMAHhCgAAAABMQLgCAAAAABMQrgAAAADABIQrAAAAADAB4QoAAAAATEC4AgAAAAATEK4AAAAAwASEKwAAAAAwAeEKAAAAAExAuAIAAAAAExCuAAAAAMAEhCsAAAAAMAHhCgAAAABMQLgCAAAAABM4PVzNmzdPgYGB8vDwUFBQkDZv3lxk/40bNyooKEgeHh5q2LChFixYYPP92NhYWSyWfLcLFy44chkAAAAAbnBODVdxcXGKiorS+PHjlZSUpLCwMPXu3VspKSkF9j948KDuuusuhYWFKSkpSS+88IJGjRql1atX2/Tz8vJSamqqzc3Dw6M0lgQAAADgBmUxDMNwVvGOHTuqffv2mj9/vrWtefPm6t+/v2JiYvL1f+6557R27Vrt3bvX2jZixAjt2rVLCQkJki4duYqKitKpU6dKPK+MjAx5e3srPT1dXl5eJR7HYinxXYtU2G+sNOuV57UBAAAAl9mTDZx25OrixYtKTExUeHi4TXt4eLi2bt1a4H0SEhLy9e/Zs6d27NihrKwsa9uZM2cUEBCgunXr6u6771ZSUlKRc8nMzFRGRobNDQAAAADs4bRwdfz4ceXk5MjX19em3dfXV2lpaQXeJy0trcD+2dnZOn78uCSpWbNmio2N1dq1a7VixQp5eHioc+fO2r9/f6FziYmJkbe3t/VWr169a1wdyjqLxTE3AAAAlF9O39DCkucvTsMw8rVdrf+V7Z06ddLDDz+stm3bKiwsTKtWrVKTJk00Z86cQsccN26c0tPTrbdDhw6VdDkAAAAAblCuzipcs2ZNubi45DtKdfTo0XxHpy7z8/MrsL+rq6tq1KhR4H0qVKigDh06FHnkyt3dXe7u7nauAAAAAAD+j9OOXLm5uSkoKEjx8fE27fHx8QoNDS3wPiEhIfn6f/XVVwoODlbFihULvI9hGEpOTladOnXMmTgAAAAAFMCppwVGR0dr8eLFeuedd7R3716NGTNGKSkpGjFihKRLp+sNHjzY2n/EiBH6448/FB0drb179+qdd97RkiVL9Oyzz1r7TJ48WevXr9eBAweUnJys4cOHKzk52TomAAAAADiC004LlKSIiAidOHFCU6ZMUWpqqlq1aqV169YpICBAkpSammpzzavAwECtW7dOY8aM0dy5c+Xv768333xT9913n7XPqVOn9PjjjystLU3e3t5q166dNm3apFtvvbXU1wcAAADgxuHU61xdr7jO1dXrlee1OaMeAAAArk9l4jpXAAAAAFCeEK4AAAAAwASEKwAAAAAwAeEKAAAAAExAuAIAAAAAExCuAAAAAMAEhCsAAAAAMAHhCgAAAABMQLgCAAAAABMQrgAAAADABIQrAAAAADAB4QoAAAAATEC4AgAAAAATEK4AAAAAwASEKwAAAAAwAeEKAAAAAExAuAIAAAAAExCuAAAAAMAEhCsAAAAAMAHhCgAAAABMQLgCAAAAABO4OnsCwI3OYnHMuIbhmHEBAABQMI5cAQAAAIAJCFcAAAAAYALCFQAAAACYgHAFAAAAACYgXAEAAACACQhXAAAAAGACwhUAAAAAmIBwBQAAAAAmIFwBAAAAgAkIVwAAAABgAldnTwBA6bJYHDOuYThmXAAAgLKCI1cAAAAAYAKOXAFwKI6UAQCAGwVHrgAAAADABIQrAAAAADAB4QoAAAAATEC4AgAAAAATEK4AAAAAwASEKwAAAAAwAeEKAAAAAExAuAIAAAAAExCuAAAAAMAEhCsAAAAAMIGrsycAAGaxWBwzrmE4ZlwAAFC+cOQKAAAAAExAuAIAAAAAExCuAAAAAMAEhCsAAAAAMIHTw9W8efMUGBgoDw8PBQUFafPmzUX237hxo4KCguTh4aGGDRtqwYIF+fqsXr1aLVq0kLu7u1q0aKGPPvrIUdMHAAAAAElODldxcXGKiorS+PHjlZSUpLCwMPXu3VspKSkF9j948KDuuusuhYWFKSkpSS+88IJGjRql1atXW/skJCQoIiJCkZGR2rVrlyIjIzVw4EBt27attJYF4AZhsTjmdr3UAwAA9rEYhvM2Ge7YsaPat2+v+fPnW9uaN2+u/v37KyYmJl//5557TmvXrtXevXutbSNGjNCuXbuUkJAgSYqIiFBGRoa++OILa59evXqpevXqWrFiRbHmlZGRIW9vb6Wnp8vLy6ukyyv1baFLs155Xltp1yvPayvteuV5baVdrzyvrbTrOTLAcpkAAHA8e7KB065zdfHiRSUmJur555+3aQ8PD9fWrVsLvE9CQoLCw8Nt2nr27KklS5YoKytLFStWVEJCgsaMGZOvz6xZswqdS2ZmpjIzM61fp6enS7r0g7welfa0SrNeeV5badcrz2sr7XrleW2lXa88r+16qeft7Zha//+t0an1HFWrsHoAIP1fJijOMSmnhavjx48rJydHvr6+Nu2+vr5KS0sr8D5paWkF9s/Oztbx48dVp06dQvsUNqYkxcTEaPLkyfna69WrV9zllCpHvrk4u155Xltp1yvPayvteuV5baVdrzyvrbzXK89rc0Y9AGXP6dOn5X2VFwunhavLLHnOlzAMI1/b1frnbbd3zHHjxik6Otr6dW5urk6ePKkaNWoUeT+zZGRkqF69ejp06NA1nYZ4PdYrz2sr7XrleW2lXa88r62065XntZV2vfK8ttKuV57XVt7rlee1lXa98ry20q5nGIZOnz4tf3//q/Z1WriqWbOmXFxc8h1ROnr0aL4jT5f5+fkV2N/V1VU1atQosk9hY0qSu7u73N3dbdqqVatW3KWYxsvLq1QejM6oV57XVtr1yvPaSrteeV5badcrz2sr7XrleW2lXa88r6281yvPayvteuV5baVZ72pHrC5z2m6Bbm5uCgoKUnx8vE17fHy8QkNDC7xPSEhIvv5fffWVgoODVbFixSL7FDYmAAAAAJjBqacFRkdHKzIyUsHBwQoJCdHChQuVkpKiESNGSLp0ut7hw4e1bNkySZd2BnzrrbcUHR2txx57TAkJCVqyZInNLoCjR49W165d9eqrr6pfv3765JNP9PXXX2vLli1OWSMAAACAG4NTw1VERIROnDihKVOmKDU1Va1atdK6desUEBAgSUpNTbW55lVgYKDWrVunMWPGaO7cufL399ebb76p++67z9onNDRUK1eu1IQJEzRx4kQ1atRIcXFx6tixY6mvr7jc3d310ksv5Ts1sTzUK89rK+165XltpV2vPK+ttOuV57WVdr3yvLbSrlee11be65XntZV2vfK8NmfUKy6nXucKAAAAAMoLp33mCgAAAADKE8IVAAAAAJiAcAUAAAAAJiBcAQAAAIAJCFelJCYmRh06dFDVqlVVu3Zt9e/fX/v27bPpYxiGJk2aJH9/f1WqVEndu3fXzz//7LB6a9asUc+ePVWzZk1ZLBYlJyc7pFZWVpaee+45tW7dWp6envL399fgwYP1119/laieJG3atEl9+/aVv7+/LBaLPv74Y5vvWyyWAm+vvfZaiWteNn/+fLVp08Z60bqQkBB98cUX1zxuYa62VkePf+TIEQ0dOlT+/v6qXLmyevXqpf379zukliTt3btX99xzj7y9vVW1alV16tTJZtdQM+sNHTo032OkU6dOJapVkOI8Dx09tpk/z7xOnz6tqKgoBQQEqFKlSgoNDdX27dtNGftqv7szZ87oqaeeUt26dVWpUiU1b95c8+fPN6V2gwYNCnz9GDlypCnjF2bevHkKDAyUh4eHgoKCtHnz5msesziPk0mTJqlZs2by9PRU9erVdccdd2jbtm0lrnm1352Z9ex5fXziiSdksVg0a9asEtUqzOHDh/Xwww+rRo0aqly5sm655RYlJiaaWkO69HPL+5j08/MzbfyifpbOeB8362+U4tYz82+wvLKzszVhwgQFBgaqUqVKatiwoaZMmaLc3NxrHrs4z3FHv9flnY/FYlFUVJRp49nzPuqo57k9CFelZOPGjRo5cqS+//57xcfHKzs7W+Hh4Tp79qy1z/Tp0zVz5ky99dZb2r59u/z8/HTnnXfq9OnTDql39uxZde7cWdOmTXPo2s6dO6edO3dq4sSJ2rlzp9asWaNffvlF99xzT4lrnj17Vm3bttVbb71V4PdTU1Ntbu+8844sFovNtv0lVbduXU2bNk07duzQjh07dNttt6lfv36mvQjndbW1OnJ8wzDUv39/HThwQJ988omSkpIUEBCgO+64w+axZEYtSfrtt9/UpUsXNWvWTN9995127dqliRMnysPDw+5axaknSb169bJ5rKxbt65EtQpSnOehI8c2++eZ16OPPqr4+HgtX75cu3fvVnh4uO644w4dPnz4mse+2u9uzJgx+vLLL/Xee+9p7969GjNmjJ5++ml98skn11x7+/btNo+Jyxem/8c//nHNYxcmLi5OUVFRGj9+vJKSkhQWFqbevXtfcxAuzuOkSZMmeuutt7R7925t2bJFDRo0UHh4uI4dO1aimlf73ZlZr7ivjx9//LG2bdsmf39/u2sU5e+//1bnzp1VsWJFffHFF9qzZ49mzJihatWqmVrnspYtW9o8Nnfv3m3a2EX9LJ3xPm7W3yjFrWfm32B5vfrqq1qwYIHeeust7d27V9OnT9drr72mOXPmXPPYxX2fceR73WXbt2/XwoUL1aZNG9PGtOd91FHPc7sZcIqjR48akoyNGzcahmEYubm5hp+fnzFt2jRrnwsXLhje3t7GggULTK93pYMHDxqSjKSkpGuuc7Val/3www+GJOOPP/645nqSjI8++qjIPv369TNuu+22a65VmOrVqxuLFy922PiXFWetZo6/b98+Q5Lx008/Wduys7MNHx8fY9GiRabWMgzDiIiIMB5++OFrGteeekOGDDH69evnkHoFKc5zw8yxHfnzPHfunOHi4mJ89tlnNu1t27Y1xo8fb2qtgn53LVu2NKZMmWLT1r59e2PChAmm1jYMwxg9erTRqFEjIzc31/SxL7v11luNESNG2LQ1a9bMeP75502tU5zHYHp6uiHJ+Prrr6+5XnFes8yqV1itP//807jpppuMn376yQgICDDeeOONa6pzpeeee87o0qWLaeMV5aWXXjLatm1bKrWK83srrfdxs/9GKaieo/8G69OnjzFs2DCbtgEDBjjk9bmg53hpvNedPn3auPnmm434+HijW7duxujRox1Sp7DXMEc+z+3FkSsnSU9PlyT5+PhIkg4ePKi0tDSFh4db+7i7u6tbt27aunWr6fUcqTi10tPTZbFYHPZ/96505MgRff755xo+fLjpY+fk5GjlypU6e/asQkJCTB/f2TIzMyXJ5kiHi4uL3NzctGXLFlNr5ebm6vPPP1eTJk3Us2dP1a5dWx07djT9NMi8vvvuO9WuXVtNmjTRY489pqNHjzqsliOfh3nHdvTPMzs7Wzk5OfmOglWqVMn0x0ZBunTporVr1+rw4cMyDEMbNmzQL7/8op49e5pa5+LFi3rvvfc0bNgwWSwWU8e+skZiYqLN678khYeHm/L6f6WrPQYvXryohQsXytvbW23btjW1tjPq5ebmKjIyUmPHjlXLli1NH3/t2rUKDg7WP/7xD9WuXVvt2rXTokWLTK9z2f79++Xv76/AwEA98MADOnDggMNqXU1pvo87mqP/BuvSpYu++eYb/fLLL5KkXbt2acuWLbrrrruueey8CnuOO/q9buTIkerTp4/uuOMOU8fNq6D1Ofp5bi/ClRMYhqHo6Gh16dJFrVq1kiSlpaVJknx9fW36+vr6Wr9nZj1HKU6tCxcu6Pnnn9egQYPk5eXl0PlI0rvvvquqVatqwIABpo25e/duValSRe7u7hoxYoQ++ugjtWjRwrTxrxfNmjVTQECAxo0bp7///lsXL17UtGnTlJaWptTUVFNrHT16VGfOnNG0adPUq1cvffXVV7r33ns1YMAAbdy40dRal/Xu3Vvvv/++vv32W82YMUPbt2/XbbfdZg2VZnLk87CgsR3986xatapCQkL08ssv66+//lJOTo7ee+89bdu2zfTHRkHefPNNtWjRQnXr1pWbm5t69eqlefPmqUuXLqbW+fjjj3Xq1CkNHTrU1HGvdPz4ceXk5Djk9f9KRT0GP/vsM1WpUkUeHh564403FB8fr5o1a5pWO6/Sqvfqq6/K1dVVo0aNMn1sSTpw4IDmz5+vm2++WevXr9eIESM0atQoLVu2zPRaHTt21LJly7R+/XotWrRIaWlpCg0N1YkTJ0yvdTWl/T7uaI78G0ySnnvuOT344INq1qyZKlasqHbt2ikqKkoPPvjgNY99pcKe445+r1u5cqV27typmJgYU8YrTGHrc/Tz3F6uzp7Ajeipp57Sjz/+WOD/3c37f0YNw7jm/1taVD2zXa1WVlaWHnjgAeXm5mrevHkOn48kvfPOO3rooYdM+5yJJDVt2lTJyck6deqUVq9erSFDhmjjxo3lLmBVrFhRq1ev1vDhw+Xj4yMXFxfdcccd6t27t+m1Ln+wt1+/fhozZowk6ZZbbtHWrVu1YMECdevWzfSaERER1n+3atVKwcHBCggI0Oeff25qGJcc+zwsaOzS+HkuX75cw4YN00033SQXFxe1b99egwYN0s6dO6957Kt588039f3332vt2rUKCAjQpk2b9OSTT6pOnTqm/p/TJUuWqHfv3qVyDr8jXv+vVNRjsEePHkpOTtbx48e1aNEiDRw4UNu2bVPt2rVNq1/a9RITEzV79mzt3LnTYUcdc3NzFRwcrKlTp0qS2rVrp59//lnz58/X4MGDTa115etu69atFRISokaNGundd99VdHS0qbWK4oz38dLiqOdgXFyc3nvvPX3wwQdq2bKlkpOTFRUVJX9/fw0ZMuSax7+ssOe4I9/rDh06pNGjR+urr74y9e+sghS0vtJ4ntuLI1el7Omnn9batWu1YcMG1a1b19p+ecefvP+H5OjRo/n+T4oZ9RzharWysrI0cOBAHTx4UPHx8aXyf7s2b96sffv26dFHHzV1XDc3NzVu3FjBwcGKiYlR27ZtNXv2bFNrXC+CgoKsQTI1NVVffvmlTpw4ocDAQFPr1KxZU66urvkCavPmzU3b3e5q6tSpo4CAgBLvhlgYRz4PCxu7NH6ejRo10saNG3XmzBkdOnRIP/zwg7Kyskx/bOR1/vx5vfDCC5o5c6b69u2rNm3a6KmnnlJERIRef/110+r88ccf+vrrr01//cirZs2acnFxMf31/0pXewx6enqqcePG6tSpk5YsWSJXV1ctWbLElNoFKY16mzdv1tGjR1W/fn25urrK1dVVf/zxh5555hk1aNDAlBp16tRx2muWp6enWrdubfrrVVGc8T5eGhz1N9hlY8eO1fPPP68HHnhArVu3VmRkpMaMGWPqkR573mfMfK9LTEzU0aNHFRQUZH2ebdy4UW+++aZcXV2Vk5NzzTWkwtdXGs9zexGuSolhGHrqqae0Zs0affvtt/n++AgMDJSfn591Vyrp0rnoGzduVGhoqOn1zFScWpdfkPfv36+vv/5aNWrUcNh8rrRkyRIFBQU5/LMDhmE45FSy64m3t7dq1aql/fv3a8eOHerXr5+p47u5ualDhw75tlj95ZdfFBAQYGqtwpw4cUKHDh1SnTp1TBnPkc/Dq41dmj9PT09P1alTR3///bfWr19v+mMjr6ysLGVlZalCBdu3MBcXF1O2Nr5s6dKlql27tvr06WPamAVxc3NTUFCQzeu/JMXHx5fo9f9KJX0MlvZrmiPqRUZG6scff1RycrL15u/vr7Fjx2r9+vWm1OjcubPTXrMyMzO1d+9e016vrsZZ7+Olwey/wfI6d+6cw16vSvIcN/O97vbbb9fu3bttnmfBwcF66KGHlJycLBcXl2sa/2rrK43nub04LbCUjBw5Uh988IE++eQTVa1a1fp/R7y9vVWpUiXrNQGmTp2qm2++WTfffLOmTp2qypUra9CgQabXk6STJ08qJSXFep2Ky28Qfn5+dl0742q1srOzdf/992vnzp367LPPlJOTY+3j4+MjNzc3u9d35swZ/frrr9avDx48qOTkZPn4+Kh+/fqSpIyMDH344YeaMWOG3eMX5YUXXlDv3r1Vr149nT59WitXrtR3332nL7/80tQ6lxVnrY4c/8MPP1StWrVUv3597d69W6NHj1b//v3zffjejFpjx45VRESEunbtqh49eujLL7/Up59+qu+++870tfn4+GjSpEm67777VKdOHf3+++964YUXVLNmTd17770lqpdXcZ6Hjhzb7J9nXuvXr5dhGGratKl+/fVXjR07Vk2bNtUjjzxyzWNf7bHSrVs3jR07VpUqVVJAQIA2btyoZcuWaebMmddcW7p0utfSpUs1ZMgQubo6/q0yOjpakZGRCg4OVkhIiBYuXKiUlBSNGDHimsa92uPk7NmzeuWVV3TPPfeoTp06OnHihObNm6c///yzxFvPF/W7q1Gjhqn1rvY4yRsAKlasKD8/PzVt2rREa8trzJgxCg0N1dSpUzVw4ED98MMPWrhwoRYuXGjK+Fd69tln1bdvX9WvX19Hjx7Vv//9b2VkZJh2WllRP0t/f/9Sfx8362+U4tYz82+wvPr27atXXnlF9evXV8uWLZWUlKSZM2dq2LBh1zz21Z7jZ86cceh7XdWqVfN9htPT01M1atQw5fPFV1tfjRo1HP48t1vpbUx4Y5NU4G3p0qXWPrm5ucZLL71k+Pn5Ge7u7kbXrl2N3bt3O6ze0qVLC+zz0ksvmVrr8jaqBd02bNhQovVt2LChwPGGDBli7fP2228blSpVMk6dOlWiGoUZNmyYERAQYLi5uRm1atUybr/9duOrr74ytcaVirNWR44/e/Zso27dukbFihWN+vXrGxMmTDAyMzMdtpYlS5YYjRs3Njw8PIy2bdsaH3/8sUPWdu7cOSM8PNyoVauWdW1DhgwxUlJSSlwvr+I8Dx09tpk/z7zi4uKMhg0bGm5uboafn58xcuRI055vV3uspKamGkOHDjX8/f0NDw8Po2nTpsaMGTNM2y59/fr1hiRj3759poxXHHPnzrW+trRv396ULfuv9jg5f/68ce+99xr+/v6Gm5ubUadOHeOee+4xfvjhhxLXLOp3Z3Y9e18fHbFF86effmq0atXKcHd3N5o1a2YsXLjQ1PEvi4iIMOrUqWNUrFjR8Pf3NwYMGGD8/PPPpo1f1M/SGe/jZv2NUtx6Zv4NlldGRoYxevRoo379+oaHh4fRsGFDY/z48SV+L73S1Z7jpfFel5eZW7GX5H3U2VuxWwzDMAQAAAAAuCZ85goAAAAATEC4AgAAAAATEK4AAAAAwASEKwAAAAAwAeEKAAAAAExAuAIAAAAAExCuAAAAAMAEhCsAAAAAMAHhCgAAE3Tv3l1RUVHXNMbvv/8ui8Wi5ORkU+YEAChdhCsAgMMNHTpUFosl3+3XX381ZfzY2FhVq1bNlLFKas2aNXr55ZedOgcAgHO5OnsCAIAbQ69evbR06VKbtlq1ajlpNoXLyspSxYoV7b6fj4+PA2YDAChLOHIFACgV7u7u8vPzs7m5uLhIkj799FMFBQXJw8NDDRs21OTJk5WdnW2978yZM9W6dWt5enqqXr16evLJJ3XmzBlJ0nfffadHHnlE6enp1iNikyZNkiRZLBZ9/PHHNvOoVq2aYmNjJf3faXirVq1S9+7d5eHhoffee0+StHTpUjVv3lweHh5q1qyZ5s2bV+T68p4W2KBBA02dOlXDhg1T1apVVb9+fS1cuNDmPj/88IPatWsnDw8PBQcHKykpKd+4e/bs0V133aUqVarI19dXkZGROn78uHXtbm5u2rx5s7X/jBkzVLNmTaWmphY5XwCA+QhXAACnWr9+vR5++GGNGjVKe/bs0dtvv63Y2Fi98sor1j4VKlTQm2++qZ9++knvvvuuvv32W/3rX/+SJIWGhmrWrFny8vJSamqqUlNT9eyzz9o1h+eee06jRo3S3r171bNnTy1atEjjx4/XK6+8or1792rq1KmaOHGi3n33XbvGnTFjhjU0Pfnkk/rnP/+p//3vf5Kks2fP6u6771bTpk2VmJioSZMm5Zt3amqqunXrpltuuUU7duzQl19+qSNHjmjgwIGS/i/QRUZGKj09Xbt27dL48eO1aNEi1alTx665AgBMYAAA4GBDhgwxXFxcDE9PT+vt/vvvNwzDMMLCwoypU6fa9F++fLlRp06dQsdbtWqVUaNGDevXS5cuNby9vfP1k2R89NFHNm3e3t7G0qVLDcMwjIMHDxqSjFmzZtn0qVevnvHBBx/YtL388stGSEhIoXPq1q2bMXr0aOvXAQEBxsMPP2z9Ojc316hdu7Yxf/58wzAM4+233zZ8fHyMs2fPWvvMnz/fkGQkJSUZhmEYEydONMLDw23qHDp0yJBk7Nu3zzAMw8jMzDTatWtnDBw40GjZsqXx6KOPFjpHAIBj8ZkrAECp6NGjh+bPn2/92tPTU5KUmJio7du32xypysnJ0YULF3Tu3DlVrlxZGzZs0NSpU7Vnzx5lZGQoOztbFy5c0NmzZ63jXIvg4GDrv48dO6ZDhw5p+PDheuyxx6zt2dnZ8vb2tmvcNm3aWP9tsVjk5+eno0ePSpL27t2rtm3bqnLlytY+ISEhNvdPTEzUhg0bVKVKlXxj//bbb2rSpInc3Nz03nvvqU2bNgoICNCsWbPsmiMAwDyEKwBAqfD09FTjxo3ztefm5mry5MkaMGBAvu95eHjojz/+0F133aURI0bo5Zdflo+Pj7Zs2aLhw4crKyuryJoWi0WGYdi0FXSfKwNabm6uJGnRokXq2LGjTb/LnxErrrwbY1gsFuv4eedVkNzcXPXt21evvvpqvu9dedrf1q1bJUknT57UyZMnTQmcAAD7Ea4AAE7Vvn177du3r8DgJUk7duxQdna2ZsyYoQoVLn1UeNWqVTZ93NzclJOTk+++tWrVstnYYf/+/Tp37lyR8/H19dVNN92kAwcO6KGHHrJ3OcXWokULLV++XOfPn1elSpUkSd9//71Nn/bt22v16tVq0KCBXF0Lfsv+7bffNGbMGC1atEirVq3S4MGD9c0331h/VgCA0sMrLwDAqV588UUtW7ZMkyZN0s8//6y9e/cqLi5OEyZMkCQ1atRI2dnZmjNnjg4cOKDly5drwYIFNmM0aNBAZ86c0TfffKPjx49bA9Rtt92mt956Szt37tSOHTs0YsSIYm2zPmnSJMXExGj27Nn65ZdftHv3bi1dulQzZ840bd2DBg1ShQoVNHz4cO3Zs0fr1q3T66+/btNn5MiROnnypB588EH98MMPOnDggL766isNGzZMOTk5ysnJUWRkpMLDw/XII49o6dKl+umnnzRjxgzT5gkAKD7CFQDAqXr27KnPPvtM8fHx6tChgzp16qSZM2cqICBAknTLLbdo5syZevXVV9WqVSu9//77iomJsRkjNDRUI0aMUEREhGrVqqXp06dLurRbX7169dS1a1cNGjRIzz77rM1nnArz6KOPavHixYqNjVXr1q3VrVs3xcbGKjAw0LR1V6lSRZ9++qn27Nmjdu3aafz48flO//P399d///tf5eTkqGfPnmrVqpVGjx4tb29vVahQQa+88op+//136xbvfn5+Wrx4sSZMmKDk5GTT5goAKB6LUZyTvgEAAAAAReLIFQAAAACYgHAFAAAAACYgXAEAAACACQhXAAAAAGACwhUAAAAAmIBwBQAAAAAmIFwBAAAAgAkIVwAAAABgAsIVAAAAAJiAcAUAAAAAJiBcAQAAAIAJ/h9jhaRBPOcNOgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Get feature importances\n",
    "importances = best_clf.feature_importances_\n",
    "\n",
    "variable_names = ['loan_amnt', 'int_rate', 'installment', 'grade' , 'emp_length' , 'home_ownership' , 'annual_inc' , 'dti' , 'delinq_2yrs' , 'inq_last_6mths' , 'open_acc' , 'pub_rec' , 'revol_bal' , 'revol_util' , 'total_acc' , 'total_pymnt' , 'total_pymnt_inv' , 'total_rec_prncp' , 'total_rec_int' , 'total_rec_late_fee' , 'recoveries' , 'collection_recovery_fee' , 'last_pymnt_amnt' , 'application_type' , 'acc_now_delinq' , 'tot_cur_bal' , 'total_rev_hi_lim']\n",
    "\n",
    "#Sort feature importances in descending order\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "#Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "\n",
    "for f in range(X_train_scaled.shape[1]):\n",
    "    print(\"%d. feature %d (%f) - %s\" % (f + 1, indices[f], importances[indices[f]], variable_names[indices[f]]))\n",
    "\n",
    "#Plot the feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X_train_scaled.shape[1]), importances[indices], color=\"b\", align=\"center\")\n",
    "plt.xticks(range(X_train_scaled.shape[1]), indices)\n",
    "plt.xlim([-1, X_train_scaled.shape[1]])\n",
    "plt.xlabel(\"Feature index\")\n",
    "plt.ylabel(\"Feature importance\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7daa8724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable corresponding to index 20: recoveries\n",
      "Variable corresponding to index 20: collection_recovery_fee\n",
      "Variable corresponding to index 20: total_rec_prncp\n",
      "Variable corresponding to index 20: grade\n",
      "Variable corresponding to index 20: int_rate\n",
      "Variable corresponding to index 20: total_rec_late_fee\n"
     ]
    }
   ],
   "source": [
    "print(\"Variable corresponding to index 20:\", variable_names[20])\n",
    "print(\"Variable corresponding to index 20:\", variable_names[21])\n",
    "print(\"Variable corresponding to index 20:\", variable_names[17])\n",
    "print(\"Variable corresponding to index 20:\", variable_names[3])\n",
    "print(\"Variable corresponding to index 20:\", variable_names[1])\n",
    "print(\"Variable corresponding to index 20:\", variable_names[19])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e1a6c8",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2a4fe621",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shero\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m5466/5466\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 983us/step - accuracy: 0.9425 - loss: 0.1705 - val_accuracy: 0.9582 - val_loss: 0.1327\n",
      "Epoch 2/50\n",
      "\u001b[1m5466/5466\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9616 - loss: 0.1225 - val_accuracy: 0.9600 - val_loss: 0.1251\n",
      "Epoch 3/50\n",
      "\u001b[1m5466/5466\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 954us/step - accuracy: 0.9631 - loss: 0.1191 - val_accuracy: 0.9610 - val_loss: 0.1229\n",
      "Epoch 4/50\n",
      "\u001b[1m5466/5466\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 933us/step - accuracy: 0.9632 - loss: 0.1165 - val_accuracy: 0.9605 - val_loss: 0.1235\n",
      "Epoch 5/50\n",
      "\u001b[1m5466/5466\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 918us/step - accuracy: 0.9637 - loss: 0.1153 - val_accuracy: 0.9615 - val_loss: 0.1209\n",
      "Epoch 6/50\n",
      "\u001b[1m5466/5466\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 937us/step - accuracy: 0.9631 - loss: 0.1161 - val_accuracy: 0.9620 - val_loss: 0.1212\n",
      "Epoch 7/50\n",
      "\u001b[1m5466/5466\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 931us/step - accuracy: 0.9637 - loss: 0.1154 - val_accuracy: 0.9613 - val_loss: 0.1202\n",
      "Epoch 8/50\n",
      "\u001b[1m5466/5466\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 966us/step - accuracy: 0.9639 - loss: 0.1139 - val_accuracy: 0.9616 - val_loss: 0.1197\n",
      "Epoch 9/50\n",
      "\u001b[1m5466/5466\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 954us/step - accuracy: 0.9636 - loss: 0.1146 - val_accuracy: 0.9622 - val_loss: 0.1193\n",
      "Epoch 10/50\n",
      "\u001b[1m5466/5466\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 940us/step - accuracy: 0.9644 - loss: 0.1118 - val_accuracy: 0.9624 - val_loss: 0.1216\n",
      "Epoch 11/50\n",
      "\u001b[1m5466/5466\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 958us/step - accuracy: 0.9644 - loss: 0.1121 - val_accuracy: 0.9608 - val_loss: 0.1212\n",
      "Epoch 12/50\n",
      "\u001b[1m5466/5466\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 930us/step - accuracy: 0.9642 - loss: 0.1121 - val_accuracy: 0.9620 - val_loss: 0.1197\n",
      "Epoch 13/50\n",
      "\u001b[1m5466/5466\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 933us/step - accuracy: 0.9646 - loss: 0.1114 - val_accuracy: 0.9626 - val_loss: 0.1169\n",
      "Epoch 14/50\n",
      "\u001b[1m5466/5466\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 956us/step - accuracy: 0.9650 - loss: 0.1100 - val_accuracy: 0.9627 - val_loss: 0.1181\n",
      "Epoch 15/50\n",
      "\u001b[1m5466/5466\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 951us/step - accuracy: 0.9653 - loss: 0.1080 - val_accuracy: 0.9630 - val_loss: 0.1169\n",
      "Epoch 16/50\n",
      "\u001b[1m5466/5466\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 943us/step - accuracy: 0.9652 - loss: 0.1096 - val_accuracy: 0.9625 - val_loss: 0.1170\n",
      "Epoch 17/50\n",
      "\u001b[1m5466/5466\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 939us/step - accuracy: 0.9657 - loss: 0.1079 - val_accuracy: 0.9621 - val_loss: 0.1177\n",
      "Epoch 18/50\n",
      "\u001b[1m5466/5466\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 933us/step - accuracy: 0.9656 - loss: 0.1077 - val_accuracy: 0.9627 - val_loss: 0.1174\n",
      "Epoch 19/50\n",
      "\u001b[1m5466/5466\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 941us/step - accuracy: 0.9649 - loss: 0.1086 - val_accuracy: 0.9632 - val_loss: 0.1168\n",
      "Epoch 20/50\n",
      "\u001b[1m5466/5466\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 952us/step - accuracy: 0.9659 - loss: 0.1068 - val_accuracy: 0.9620 - val_loss: 0.1172\n",
      "Epoch 21/50\n",
      "\u001b[1m5466/5466\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 970us/step - accuracy: 0.9656 - loss: 0.1072 - val_accuracy: 0.9618 - val_loss: 0.1205\n",
      "Epoch 22/50\n",
      "\u001b[1m5466/5466\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9649 - loss: 0.1089 - val_accuracy: 0.9632 - val_loss: 0.1171\n",
      "Epoch 23/50\n",
      "\u001b[1m5466/5466\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 953us/step - accuracy: 0.9663 - loss: 0.1058 - val_accuracy: 0.9627 - val_loss: 0.1184\n",
      "Epoch 24/50\n",
      "\u001b[1m5466/5466\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 936us/step - accuracy: 0.9656 - loss: 0.1074 - val_accuracy: 0.9627 - val_loss: 0.1221\n",
      "Epoch 25/50\n",
      "\u001b[1m5466/5466\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 952us/step - accuracy: 0.9662 - loss: 0.1053 - val_accuracy: 0.9633 - val_loss: 0.1181\n",
      "Epoch 26/50\n",
      "\u001b[1m5466/5466\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 971us/step - accuracy: 0.9666 - loss: 0.1040 - val_accuracy: 0.9634 - val_loss: 0.1168\n",
      "Epoch 27/50\n",
      "\u001b[1m5466/5466\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 948us/step - accuracy: 0.9660 - loss: 0.1051 - val_accuracy: 0.9627 - val_loss: 0.1172\n",
      "Epoch 28/50\n",
      "\u001b[1m5466/5466\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 944us/step - accuracy: 0.9666 - loss: 0.1039 - val_accuracy: 0.9620 - val_loss: 0.1177\n",
      "Epoch 29/50\n",
      "\u001b[1m5466/5466\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 956us/step - accuracy: 0.9665 - loss: 0.1040 - val_accuracy: 0.9634 - val_loss: 0.1163\n",
      "Epoch 30/50\n",
      "\u001b[1m5466/5466\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 936us/step - accuracy: 0.9669 - loss: 0.1028 - val_accuracy: 0.9636 - val_loss: 0.1170\n",
      "Epoch 31/50\n",
      "\u001b[1m5466/5466\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 958us/step - accuracy: 0.9666 - loss: 0.1042 - val_accuracy: 0.9623 - val_loss: 0.1183\n",
      "Epoch 32/50\n",
      "\u001b[1m5466/5466\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 955us/step - accuracy: 0.9668 - loss: 0.1024 - val_accuracy: 0.9627 - val_loss: 0.1167\n",
      "Epoch 33/50\n",
      "\u001b[1m5466/5466\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 951us/step - accuracy: 0.9661 - loss: 0.1042 - val_accuracy: 0.9638 - val_loss: 0.1161\n",
      "Epoch 34/50\n",
      "\u001b[1m5466/5466\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 961us/step - accuracy: 0.9668 - loss: 0.1035 - val_accuracy: 0.9633 - val_loss: 0.1190\n",
      "Epoch 35/50\n",
      "\u001b[1m5466/5466\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 983us/step - accuracy: 0.9665 - loss: 0.1026 - val_accuracy: 0.9632 - val_loss: 0.1162\n",
      "Epoch 36/50\n",
      "\u001b[1m5466/5466\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 983us/step - accuracy: 0.9675 - loss: 0.1011 - val_accuracy: 0.9635 - val_loss: 0.1165\n",
      "Epoch 37/50\n",
      "\u001b[1m5466/5466\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 945us/step - accuracy: 0.9675 - loss: 0.1010 - val_accuracy: 0.9618 - val_loss: 0.1185\n",
      "Epoch 38/50\n",
      "\u001b[1m5466/5466\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 936us/step - accuracy: 0.9671 - loss: 0.1027 - val_accuracy: 0.9624 - val_loss: 0.1201\n",
      "Epoch 39/50\n",
      "\u001b[1m5466/5466\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 944us/step - accuracy: 0.9668 - loss: 0.1029 - val_accuracy: 0.9626 - val_loss: 0.1174\n",
      "Epoch 40/50\n",
      "\u001b[1m5466/5466\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 961us/step - accuracy: 0.9674 - loss: 0.1010 - val_accuracy: 0.9612 - val_loss: 0.1212\n",
      "Epoch 41/50\n",
      "\u001b[1m5466/5466\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 981us/step - accuracy: 0.9669 - loss: 0.1012 - val_accuracy: 0.9610 - val_loss: 0.1222\n",
      "Epoch 42/50\n",
      "\u001b[1m5466/5466\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 966us/step - accuracy: 0.9671 - loss: 0.1028 - val_accuracy: 0.9627 - val_loss: 0.1198\n",
      "Epoch 43/50\n",
      "\u001b[1m5466/5466\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 941us/step - accuracy: 0.9666 - loss: 0.1029 - val_accuracy: 0.9632 - val_loss: 0.1191\n",
      "Epoch 44/50\n",
      "\u001b[1m5466/5466\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 951us/step - accuracy: 0.9673 - loss: 0.1010 - val_accuracy: 0.9625 - val_loss: 0.1193\n",
      "Epoch 45/50\n",
      "\u001b[1m5466/5466\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 947us/step - accuracy: 0.9673 - loss: 0.1015 - val_accuracy: 0.9623 - val_loss: 0.1188\n",
      "Epoch 46/50\n",
      "\u001b[1m5466/5466\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 941us/step - accuracy: 0.9681 - loss: 0.0995 - val_accuracy: 0.9622 - val_loss: 0.1187\n",
      "Epoch 47/50\n",
      "\u001b[1m5466/5466\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 941us/step - accuracy: 0.9676 - loss: 0.1000 - val_accuracy: 0.9618 - val_loss: 0.1214\n",
      "Epoch 48/50\n",
      "\u001b[1m5466/5466\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 934us/step - accuracy: 0.9678 - loss: 0.0999 - val_accuracy: 0.9628 - val_loss: 0.1189\n",
      "Epoch 49/50\n",
      "\u001b[1m5466/5466\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 935us/step - accuracy: 0.9671 - loss: 0.1012 - val_accuracy: 0.9621 - val_loss: 0.1220\n",
      "Epoch 50/50\n",
      "\u001b[1m5466/5466\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 963us/step - accuracy: 0.9674 - loss: 0.1005 - val_accuracy: 0.9630 - val_loss: 0.1201\n",
      "\u001b[1m6832/6832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 620us/step - accuracy: 0.9681 - loss: 0.0990\n",
      "\u001b[1m6835/6835\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 608us/step - accuracy: 0.9627 - loss: 0.1217\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Standardize the features\n",
    "#Note we are peroforming scaling the orignal X_train and Y_train and not the already scaled data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the neural network architecture for binary classification\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')  # Output layer with 1 neuron and sigmoid activation\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',  # Using binary cross-entropy as the loss function for binary classification\n",
    "              metrics=['accuracy'])  # Monitor accuracy during training\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on the training and test data\n",
    "train_loss, train_accuracy = model.evaluate(X_train_scaled, y_train)\n",
    "test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e79a9298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6832/6832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 611us/step\n",
      "\u001b[1m6835/6835\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 596us/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Make predictions for both training and test data\n",
    "y_train_pred = model.predict(X_train_scaled)\n",
    "y_test_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate MSE for both training and test data\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c5df9fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9673702120780945\n",
      "Train MSE: 0.02748277003053054\n",
      "Test Accuracy: 0.962897777557373\n",
      "Test MSE: 0.031605380302150855\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Accuracy:\", train_accuracy)\n",
    "print(\"Train MSE:\", train_mse)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "print(\"Test MSE:\", test_mse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
